{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4d20436fa6a64bc9b7f1d8040b9bdbb2",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<div class=\"green\">\n",
    "    \n",
    "# <span style=\"color:green\">Consumer Complaint Response</span>\n",
    "    \n",
    "#### <span style=\"color:lightgreen\">GitHubs: [Tyler Kephart](https://github.com/tkephart96) | [Chellyan Moreno](https://github.com/chellyan-moreno) | [Rosendo Lugo](https://github.com/rosendo-lugo) | [Alexia Lewis](https://github.com/lewisalexia)</span>\n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9256d39675cd441bb50f004e817e6aa1",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<div class=\"alert alert-success\">    \n",
    "    \n",
    "## Goal: \n",
    "This classification NLP project aims to provide an accurate prediction of company response based on the language of a consumer's complaint.\n",
    "\n",
    "## Description:\n",
    "\n",
    "Our project involves analyzing 3.5 million consumer complaints to the Consumer Financial Protection Bureau (CFPB) from 2011 to 2023. We'll use Natural language Processing to analyze how the wording of complaints affects a company's response. Our goal is to provide insights on complaint language and its impact, helping companies improve their responses and enhancing the outcomes for consumers and businesses.\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "093d90dd38e04eeeb2042b39ec8860a3",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# <span style=\"color:green\">Imports</span>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "b076c25abc214e2ca956e0ba387521b0",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "#local modules\n",
    "import wrangle as wr\n",
    "import explore as ex\n",
    "import model as mo\n",
    "\n",
    "#standard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "#file\n",
    "import os\n",
    "import json\n",
    "\n",
    "#vizz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "#preprocess\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "#split and model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#set random state\n",
    "random_state=123\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "847202ed27164ed9b3d11d931c0a1d6b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# <span style=\"color:green\">Wrangle</span>\n",
    "    \n",
    "\n",
    "---\n",
    "\n",
    "* <span style=\"color:green\">Data acquired from [Google BigQuery](https://console.cloud.google.com/marketplace/product/cfpb/complaint-database)\n",
    "* <span style=\"color:green\">3,458,906 rows × 18 columns *before* cleaning\n",
    "* <span style=\"color:green\">1,246,736 rows x 8 columns *after* cleaning</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e28b340f83d3466896df99eb4b0d3ae9",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "### <span style=\"color:lightgreen\">Data Dictionary</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1c190b1550fc42d0a7207cd7dca8479f",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "| Feature                               | Definition                                                                                  |\n",
    "| :------------------------------------ | :------------------------------------------------------------------------------------------ |\n",
    "| date_received                         | Date the complaint was received by the CFPB                                                 |\n",
    "| product                               | The type of product the consumer identified in the complaint                                |\n",
    "| subproduct                            | The type of sub-product the consumer identified in the complaint                            |\n",
    "| issue                                 | The issue the consumer identified in the complaint                                          |\n",
    "| subissue                              | The sub-issue the consumer identified in the complaint                                      |\n",
    "| consumer_complaint_narrative          | A description of the complaint provided by the consumer                                     |\n",
    "| company_public_response               | The company's optional public-facing response to a consumer's complaint                     |\n",
    "| company_name                          | Name of the company identified in the complaint by the consumer                             |\n",
    "| state                                 | Two-letter postal abbreviation of the state of the mailing address provided by the consumer |\n",
    "| zip_code                              | The mailing ZIP code provided by the consumer                                               |\n",
    "| tags                                  | Older American is aged 62 and older, Servicemember is Active/Guard/Reserve member or spouse |\n",
    "| consumer_consent_provided             | Identifies whether the consumer opted in to publish their complaint narrative               |\n",
    "| submitted_via                         | How the complaint was submitted to the CFPB                                                 |\n",
    "| date_sent_to_company                  | The date the CFPB sent the complaint to the company                                         |\n",
    "| company_response_to_consumer (target) | The response from the company about this complaint                                          |\n",
    "| timely_response                       | Indicates whether the company gave a timely response or not                                 |\n",
    "| consumer_disputed                     | Whether the consumer disputed the company's response                                        |\n",
    "| complaint_id                          | Unique ID for complaints registered with the CFPB                                           |\n",
    "| product_bins                          | Engineered Feature: bin related products together                                           |\n",
    "| clean                                 | Engineered Feature: tokenized, numbers/specials, and XX's removed                           |\n",
    "| lemon                                 | Engineered Feature: clean column PLUS lemmatization                                         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire and write/read CSV\n",
    "df = wr.check_file_exists_gbq('cfpb.csv', 'service_key.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b1bd204735124722bc7543694d9fdf67",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<div class=\"alert alert-success\">    \n",
    "\n",
    "### Insight: \n",
    "\n",
    "* **Quick run**\n",
    "    * Verify `import wrangle as w` is in the imports section \n",
    "    * Run final report\n",
    "    * This will use a pre-built and cleaned parquet file\n",
    "<br>\n",
    "<br>\n",
    "* **For the longer run: ⚠️WARNING⚠️:** These are almost the same steps we took to originally acquire the data. The steps take a lot of time (and space) and may not even be the best way of doing it. We highly recommend doing the quick run above unless you want to know how we got the data.\n",
    "    * Verify `import big_wrangle as w` is in the imports section\n",
    "    * Install the pandas-gbq package\n",
    "        * `pip install pandas-gbq`\n",
    "    * Go to Google BigQuery and create a project\n",
    "    * Copy the `'long-SQL queries found in big_wrangle.py`\n",
    "        * Run in [Google BigQuery](https://cloud.google.com/bigquery/public-data)\n",
    "    * Click on 'Go to Datasets in Cloud Marketplace' and search for 'CFPB'\n",
    "        * View the dataset to open a quick SQL prompt to query in\n",
    "    * Save each result as a BigQuery table in your project\n",
    "    * You can look in `big_wrangle.py for what we named our project, database, and tables`\n",
    "    * Edit and save the `'small-SQL query variables found in big_wrangle.py` to the respective table names in your BigQuery project using this format: \n",
    "        * ***FROM 'database. table' and edit the 'project_ID' variable to your project's ID***\n",
    "    * Run final report\n",
    "    * It may ask for authentication when it tries to query Google BigQuery\n",
    "        * Try to run again if it stopped\n",
    "    * This will run through the longer pathway of getting the datasets from the source and merging/cleaning/prep\n",
    "    * It will probably take a while **(3+ millions of rows, +2GB)**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3ee16d073c2f426b95f4050a2414ce09",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# <span style=\"color:green\">Prepare</span>  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "916f2a7dc0344637be7a88256fc70aae",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### **<span style=\"color:lightgreen\">Dropped Columns</span>**\n",
    "  * **product**\n",
    "    * 0% nulls\n",
    "    * **<span style=\"color:lightblue\">ENGINEERED FEATURE</span>**\n",
    "    * *<span style=\"color:lightblue\">bin related products/services together then drop</span>*\n",
    "        * <span style=\"color:lightgreen\">bins = credit_report, credit_card, debt_collection, mortgage, bank, loans, and money_service</span>\n",
    "  * **subproduct**\n",
    "    * 7% null\n",
    "  * **issue**\n",
    "    * 0% nulls\n",
    "    * 165 unique values\n",
    "    * **<span style=\"color:lightblue\">future iteration</span>**\n",
    "  * **subissue**\n",
    "    * 20% null\n",
    "    * 221 unique\n",
    "  * **consumer_complaint_narrative**\n",
    "    * 64% null\n",
    "    * renamed to narrative\n",
    "      * **<span style=\"color:lightblue\">drop all null values</span>**\n",
    "      * **<span style=\"color:lightblue\">drop after NLTK cleaning</span>**\n",
    "  * **company_public_response**\n",
    "    * 56% null\n",
    "    * related to target\n",
    "  * **zip code**\n",
    "    * 1% null\n",
    "    * mixed data types\n",
    "      * **<span style=\"color:lightblue\">future iteration</span>**\n",
    "  * **consumer_consent_provided**\n",
    "    * 25% null\n",
    "    * does not relate to the target\n",
    "  * **submitted_via**\n",
    "    * 0% nulls\n",
    "    * does not relate to the target\n",
    "  * **date_sent_to_company**\n",
    "    * 0% nulls\n",
    "      * **<span style=\"color:lightblue\">future iteration</span>**\n",
    "  * **timely_response**\n",
    "    * 0% nulls\n",
    "    * boolean\n",
    "      * **<span style=\"color:lightblue\">future iteration</span>**\n",
    "  * **consumer_disputed**\n",
    "    * 77% null\n",
    "      * **<span style=\"color:lightblue\">future iteration</span>**\n",
    "  * **complaint_id**\n",
    "    * 0% nulls\n",
    "<br>\n",
    "\n",
    "---\n",
    "### **<span style=\"color:lightgreen\">Cleaned Columns</span>**\n",
    "  * **date_received**\n",
    "    * 0% nulls\n",
    "    * changed date to DateTime\n",
    "  * **company_name**\n",
    "    * 0% nulls\n",
    "    * 6,694 Companies\n",
    "  * **state**\n",
    "    * 1% null\n",
    "    * keep for purposes of exploration\n",
    "      * **<span style=\"color:lightblue\">impute 1% null into UNKNOWN label</span>**\n",
    "  * **tags**\n",
    "    * 89% null\n",
    "        * **<span style=\"color:lightblue\">impute nulls with \"Average Person label</span>**\n",
    "  * **company_response_to_consumer**\n",
    "    * Target\n",
    "    * 4 nulls = 0%\n",
    "      * **<span style=\"color:lightblue\">drop these 4 rows because this is the target column</span>**\n",
    "    * 8 initial unique values\n",
    "      * **<span style=\"color:lightblue\">nice to have: apply the model to in_progress complaints and see what it predicts based on the language</span>**\n",
    "      * **<span style=\"color:lightblue\">drop 'in progress' response because there is no conclusion</span>**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "df_clean = wr.clean_data(df)\n",
    "# Write to Parquet\n",
    "df_clean.to_parquet('df_clean.parquet')\n",
    "# Assign\n",
    "df_clean = pd.read_parquet('df_clean.parquet')\n",
    "\n",
    "# Prep\n",
    "df_prep = wr.prep_narrative(df_clean)\n",
    "# Write to Parquet\n",
    "df_prep.to_parquet('df_prep.parquet')\n",
    "# Assign\n",
    "df_prep = pd.read_parquet('df_prep.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "### **NOTE** After the initial notebook run:\n",
    "1. Comment out the above cell\n",
    "2. Uncomment the cell below \n",
    "3. Run cell to call from the parquet file for faster iteration.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assign\n",
    "# df_clean = pd.read_parquet('df_clean.parquet')\n",
    "# # Assign\n",
    "# df_prep = pd.read_parquet('df_prep.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5ca865c3ceb844f7b656bb0541e40888",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<div class=\"alert alert-success\">    \n",
    "\n",
    "### Insight:\n",
    "    \n",
    "Used NLTK to clean each document resulting in:\n",
    "* 2 new columns: *clean* (removes redacted XXs, and stopwords removed) and *lemon* (lemmatized)\n",
    "    <br>\n",
    "    <br>\n",
    "    \n",
    "Selected columns to proceed with after cleaning:\n",
    "* date_received, product_bins, company_name, state, tags, company_response_to_customer (target), clean, lemon\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fb82a0fe7a794debb505984fdff6ff38",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# <span style=\"color:green\">Explore</span>\n",
    "    \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:lightgreen\">Split and Parquet</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "train, validate, test = wr.split_data(df_prep,\"company_response_to_consumer\")\n",
    "\n",
    "# Write to Parquet\n",
    "train.to_parquet('train.parquet')\n",
    "validate.to_parquet('validate.parquet')\n",
    "test.to_parquet('test.parquet')\n",
    "\n",
    "# Assign \n",
    "train = pd.read_parquet('train.parquet')\n",
    "validate = pd.read_parquet('validate.parquet')\n",
    "test = pd.read_parquet('test.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "81bd3a3ba7fd444aa60448c5d6f06979",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">  \n",
    "    \n",
    "## <span style=\"color:darkgreen\">Questions To Answer:</span>\n",
    "\n",
    "**1. Are there words that get particular responses and is there a relationship?**\n",
    "* What are the payout words that got a company response of closed with monetary relief?\n",
    "* Are there unique words associated with products? Is there a relationship between unique product words and responses?\n",
    "<br>\n",
    "\n",
    "**2. Do all responses have a negative sentiment?**\n",
    "* Do narratives with a neutral or positive sentiment analysis relating to bank account products lead to a response of closed with monetary relief?\n",
    "<br>\n",
    "\n",
    "**3. Are there unique words associated with the most negative and most positive company responses?**\n",
    "<br>\n",
    "\n",
    "**4. Which product is more likely to have monetary relief?**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "de788727c8b34a9699e11fb7cb914aa7",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### <span style=\"color:lightblue\">**1. Are there words that get particular company responses and is there a relationship?**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0$: This notebook is not pretty\n",
    "\n",
    "\n",
    "$H_a$: This notebook is pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1183737517674afeaedd643c2a9f7022",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "source": [
    "Initial Thoughts:\n",
    "* Separation each word by row and then will be doing a count of how many times the word appears in the lemon column.\n",
    "* Use a small sample in this case we will only use a max_features of 20,000\n",
    "* Count Words: Use a tool like CountVectorizer in Python to count how often each word appears in the complaints.\n",
    "* Compare: Calculate the average count of each word for each type of company response to see which words are used most often.\n",
    "* Visualize: Create a barplot visual to show which words are most associated with each type of company response.\n",
    "* Use your word counts to predict the company response using machine learning techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts, df_with_words,word_counts_ones = ex.get_word_counts(train)\n",
    "top = ex.top_15_words(word_counts_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "40b626c6b14e40a7a2bf3cef1da8f4a4",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.frequenct_words_plot(df_with_words,word_counts_ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "154f7fc2cefa4d1881afc8091de13bd1",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<div class=\"alert alert-success\">    \n",
    "\n",
    "## Insight:\n",
    "* Based on the top 15 words there are no specific words that are associated with a specific respond.   \n",
    "\n",
    "* Common Words: \n",
    "    The most common words in all company responses are: \n",
    "    account,\n",
    "    credit,\n",
    "    report,\n",
    "    information,\n",
    "    payment,\n",
    "    loan,\n",
    "    time,\n",
    "    would,\n",
    "    debt,\n",
    "    company,\n",
    "    and \"day\"     \n",
    "* No Specific Words: \n",
    "    There are no specific words that are only associated with a certain type of company response. This means companies use similar language regardless of their response type. \n",
    "    \n",
    "* Account is Popular: \n",
    "    The word account is the most frequently used word in company responses. This suggests that many complaints are related to issues with accounts.  \n",
    "    \n",
    "* Response Types: \n",
    "    The response type \"Closed with explanation\" has the highest word count for all the top words. This means that companies tend to use more words when they are providing an explanation. \n",
    "    \n",
    "* Less Words for \"Untimely response\": \n",
    "    Companies use fewer words in their responses when the response is \"Untimely response\". This could mean that when companies respond late, they tend to provide less detailed responses. \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a3ef2e287a3d490aadfd13ff296541d7",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### <span style=\"color:lightblue\">**2. Do all responses have a negative sentiment?**</span>\n",
    "* <span style=\"color:lightblue\">Do narratives with a neutral or positive sentiment analysis relating to bank account products lead to a response of closed with monetary relief? </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0$: There is no significant effect of sentiment on company response to the consumer.\n",
    "\n",
    "\n",
    "$H_a$: There is a significant effect of sentiment on company response to the consumer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize data and run statistical analysis\n",
    "ex.analyze_sentiment(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0f6a8c14418a4c26a0fb3bf442db4d4c",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<div class=\"alert alert-success\">    \n",
    "\n",
    "### Insight: \n",
    "#### - Overall, there is a strong correlation between the sentiment of consumer complaints/narratives and the corresponding responses from companies.\n",
    "\n",
    "1. **Mortgage**:\n",
    "  - Consumer complaints/narratives exhibit predominantly positive sentiment, and companies provide an equal distribution of responses across different categories.\n",
    "  \n",
    "2. **Credit Report**:\n",
    "  - Consumer complaints/narratives with positive sentiment tend to receive the \"closed with monetary relief\" response most frequently.\n",
    "  - Overall, the sentiment of complaints/narratives is generally neutral to positive.\n",
    "  \n",
    "3. **Debt Collection**:\n",
    "  - All consumer complaints/narratives have negative sentiment scores, and the complaints with the most negative scores typically receive an \"untimely response.\"\n",
    "  \n",
    "4. **Loans**:\n",
    "  - Complaints/narratives regarding loans have sentiment scores ranging from neutral to positive. Companies provide different responses irrespective of the sentiment score.\n",
    "   \n",
    "5. **Bank**:\n",
    "  - Sentiment scores for bank-related complaints/narratives are somewhat mixed, ranging from neutral to negative. The more negative complaints tend to receive a \"closed\" or \"untimely response.\"\n",
    "  \n",
    "6. **Money Service**:\n",
    "  - Sentiment scores for complaints/narratives about money services vary between negative and positive. The most negative complaints receive a \"closed\" response.\n",
    "  \n",
    "7. **Credit Card**:\n",
    " - The majority of sentiment scores for credit card complaints/narratives range from neutral to positive. The most common response received by consumers is \"closed with non-monetary relief.\"\n",
    " \n",
    " \n",
    "#### - These findings indicate that the sentiment of consumer complaints/narratives has an influence on the type of response received from companies across different industry sectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "069962b4a3fb484ba87278b8685f5272",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### <span style=\"color:lightblue\">**3. Are there unique words associated with the most negative and most positive company responses?**</span>\n",
    "* <span style=\"color:lightblue\">Are there unique words associated with products? Is there a relationship between unique product words and responses?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0$: There are no unqiue words associated with products and the words cannot provide an educated guess for company response.\n",
    "\n",
    "\n",
    "$H_a$: There are unqiue words associated with products and the words can provide an educated guess for company response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4b7c26b7097440bfa60cdbb2d95b0321",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Get words per company response and per product\n",
    "word_counts = ex.get_words(train).sort_values(by='all',ascending=False)\n",
    "word_counts = word_counts.sort_values(by='all',ascending=False)\n",
    "word_counts_products = ex.get_words_products(train)\n",
    "word_counts_products = word_counts_products.sort_values(by='all',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "59579ba9acd34b79b8df417d16732c6a",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize words per company response\n",
    "ex.unique_words(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize words per product\n",
    "ex.unique_words(word_counts_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "93d31283b1834f3380d103ea66c9cf02",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## Insight:\n",
    "\n",
    "There is a relationship between words used in complaints and company responses. The words used relate to products that consumer's can complain about. There are unique words associated with each product and those words can be used to predict a company response.\n",
    "    \n",
    "### Company Responses and top 5 words:\n",
    "\n",
    "* Explanation\n",
    "    * Account, Credit, Report, Payment, Information\n",
    "        * This type of response looks like it could relate to credit reporting products\n",
    "* Non-Monetary\n",
    "    * Credit, Account, Report, Information, Reporting\n",
    "* **Monetary**\n",
    "    * Account, **Bank**, **Card**, Credit, Payment\n",
    "        * This type of response looks like it could relate to credit card or bank products\n",
    "* **Untimely Reponse**\n",
    "    * **Debt**, Credit, Account, **Company**, **Loan**\n",
    "        * This type of response looks like it could relate to debt products\n",
    "* Closed\n",
    "    * Account, Debt, Credit, Payment, Loan\n",
    "---\n",
    "\n",
    "### Products and top 5 words:\n",
    "* Credit Report\n",
    "    * Credit, Account, Report, Information, Reporting\n",
    "        * matches up with hypothesis where this type of product might get a response of explanation or non-monetary relief\n",
    "* Debt\n",
    "    * **Debt**, Credit, Account, **Collection**, Report\n",
    "        * matches up with hypothesis where this type of product might get an untimely response\n",
    "* Credit Card\n",
    "    * **Card**, Credit, Account, Payment, **Charge**\n",
    "        * matches up with hypothesis where this type of product might get a response of monetary relief\n",
    "* Mortgage\n",
    "    * Payment, Loan, Mortgage, Would, **Time**\n",
    "        * matches up with hypothesis where this type of product might get a response of closed\n",
    "* Loans\n",
    "    * Loan, Payment, Account, Would, Credit\n",
    "        * matches up with hypothesis where this type of product might get a response of closed\n",
    "* Bank\n",
    "    * Account, Bank, **Check**, Money, Would\n",
    "        * matches up with hypothesis where this type of product might get a response of monetary relief\n",
    "* Money Service\n",
    "    * Account, Money, Bank, **Paypal**, **Transaction**\n",
    "        * matches up with hypothesis where this type of product might get a response of monetary relief\n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8231a29d029b4659a98e879cd328018b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### <span style=\"color:lightblue\">**4. Which product is more likely to have monetary relief?**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "5e32e170360246448bb61d7bbb061049",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "#visualize products and their proportions of monetary relief\n",
    "ex.monetary_product(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c13f957f7ab54f76806462f23c0e765d",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<div class=\"alert alert-success\">    \n",
    "\n",
    "### Insight: \n",
    "\n",
    "Credit card and bank related products have the highest chance of getting monetary relief at just under 20% of their total complaints. As for credit report products, we can see that they have the least chance of getting monetary relief.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">  \n",
    "    \n",
    "## <span style=\"color:darkgreen\">Exploration Summary:</span>\n",
    "    \n",
    "* There are no specific words associated with a particular type of response in company responses.\n",
    "* The most common words in company responses include account, credit, report, information, payment, loan, time, debt, company, and day.\n",
    "* The response type \"Closed with explanation\" has the highest word count among the top words, suggesting that companies provide more detailed explanations in their responses.\n",
    "* Companies tend to use fewer words in their responses when the response type is \"Untimely response,\" possibly indicating less detailed explanations.\n",
    "* The sentiment of consumer complaints/narratives correlates with the corresponding responses from companies across different industry sectors.\n",
    "* Different product categories receive different types of responses based on the sentiment of the complaints/narratives.\n",
    "* The analysis of words used in complaints and company responses suggests that specific words can be associated with certain product categories and used to predict the type of response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9e8cd22252ae47219f9db426140e1921",
    "deepnote_cell_type": "markdown",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1689004677738,
    "source_hash": "acbafe96"
   },
   "source": [
    "# <span style=\"color:green\">Modeling</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "787b93405bea40e2b3cf4c44a1fe4107",
    "deepnote_cell_type": "code"
   },
   "source": [
    "<div class=\"alert alert-success\">  \n",
    "\n",
    "## <span style=\"color:darkslategray\">Selected Classification Models:</span>\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- KNN\n",
    "- Logistic Regression\n",
    "- Multinomial NB\n",
    "- Complement NB\n",
    "- Categorical NB\n",
    "\n",
    "### <span style=\"color:darkslategray\">Evaluation Metric:</span>\n",
    "- Accuracy\n",
    "    * **<span style=\"color:blue\">Baseline: 78%</span>**\n",
    "\n",
    "### <span style=\"color:darkslategray\">Features Sent In:</span>\n",
    "- Top 2,900 words in 'lemon' column\n",
    "\n",
    "### <span style=\"color:darkslategray\">Data Sample:</span>\n",
    "- Calculated the sample size for each class category using a 20% sampling rate.\n",
    "\n",
    "- Created smaller datasets by sampling the specified number of samples from each class category.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f10b0b2178c448a8914d28964a822b5e",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<div class=\"alert alert-success\">    \n",
    "\n",
    "### Insight: \n",
    "   - All models did not exceed our expectations.\n",
    "   \n",
    "- The best-performing model on our train and validate data is a Decision Tree Classifier with a max depth of 9 and minimum sample leaf of 11.\n",
    "- The validate data score was 79.35%. We decided to run it on the test data, and it gave us a score of 79.36%.\n",
    "- We plan to experiment with different features, types of grams combinations, and metrics to improve our model's prediction percentage.\n",
    "    \n",
    "''\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f10b0b2178c448a8914d28964a822b5e",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<div class=\"alert alert-success\">  \n",
    "    \n",
    "## <span style=\"color:darkgreen\">Modeling Summary:</span>\n",
    "    \n",
    "* we found that a Decision Tree Classifier with a max depth of 9 and minimum sample leaf of 11 performed the best on our train, validate and test data. However, all models fell short of our expectations, prompting us to explore different feature combinations, types of grams, and evaluation metrics to enhance our model's prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "995bb2ff3e6042b1824bcff6ca576413",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# <span style=\"color:green\">Conclusion</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">  \n",
    "\n",
    "<div class=\"alert alert-success\"> \n",
    "\n",
    "\n",
    "# Project Summary:\n",
    "\n",
    "* The analysis revealed a significant relationship between consumer sentiment in complaints/narratives and the corresponding company responses, indicating the importance of sentiment in consumer-company interactions.\n",
    "* Sentiment patterns varied across industries, with positive sentiment in mortgage complaints, credit report complaints receiving \"closed with monetary relief\" responses, and consistently negative sentiment in debt collection complaints leading to \"untimely response\" from companies. These findings highlight the need to consider sentiment for effective consumer grievance resolution.\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a2b5e87f4c1249cb9a70b19f113b6a33",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# <span style=\"color:green\">Recommendations and Next Steps</span>\n",
    "\n",
    "---\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f10b0b2178c448a8914d28964a822b5e",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<div class=\"alert alert-success\">    \n",
    "\n",
    "    \n",
    "## Recommendations\n",
    "\n",
    "* \n",
    "* \n",
    "* \n",
    "* \n",
    "\n",
    "## Next Steps\n",
    "* \n",
    "* \n",
    "    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7c6d32a08ace409285566694aef0167d",
    "deepnote_cell_type": "markdown"
   },
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "6e76cfdb7dfe4f4caf85c9305effad9d",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
