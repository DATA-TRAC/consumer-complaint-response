{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports loaded successfully, awaiting commands...\n"
     ]
    }
   ],
   "source": [
    "# data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# visuals\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# nlp\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# modeling\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# local\n",
    "import wrangle as w\n",
    "import model as m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parquet file found and loaded\n"
     ]
    }
   ],
   "source": [
    "df = w.wrangle_complaints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "relief = ['Closed with monetary relief', 'Closed with non-monetary relief']\n",
    "no_relief = ['Closed with explanation']\n",
    "df = df[df['company_response_to_consumer'] != \"Untimely response\"]\n",
    "df = df[df['company_response_to_consumer'] != \"Closed\"]\n",
    "df['response'] = np.where(df['company_response_to_consumer'].isin(relief),'relief','')\n",
    "df['response'] = np.where(df['company_response_to_consumer'].isin(no_relief),'no_relief',df['response'])\n",
    "df = df.drop(columns='company_response_to_consumer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared DF: (1238536, 7)\n",
      "Train: (743121, 7)\n",
      "Validate: (247707, 7)\n",
      "Test: (247708, 7)\n"
     ]
    }
   ],
   "source": [
    "train, val, test = w.split_data(df,'response')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(df):\n",
    "    '''Encode categorical columns'''\n",
    "    # columns to encode\n",
    "    cols = ['tags','product_bins']\n",
    "    # encode the dummies\n",
    "    dummy = pd.get_dummies(df[cols],prefix='',prefix_sep='',drop_first=True)\n",
    "    # bring the dummies along\n",
    "    return pd.concat([df,dummy],axis=1)\n",
    "\n",
    "def process_data_modeling(train, validate, test):\n",
    "    \"\"\"\n",
    "    The function `process_data_modeling` reads data from parquet files, performs data sampling,\n",
    "    encoding, and splits the data into training, validation, and test sets.\n",
    "    \n",
    "    :param train: The `train` parameter is the training dataset, which is a pandas DataFrame containing\n",
    "    the data for training the model\n",
    "    :param validate: The `validate` parameter is a DataFrame that contains the validation data. It is\n",
    "    read from a parquet file named 'validate.parquet'\n",
    "    :param test: The `test` parameter is a DataFrame that contains the test data for your model. It is\n",
    "    read from a parquet file named 'test.parquet'\n",
    "    :return: six variables: X_train, y_train, X_val, y_val, X_test, and y_test.\n",
    "    \"\"\"\n",
    "    random_state = 123\n",
    "    response_categories = [\n",
    "        'relief',\n",
    "        'no_relief'\n",
    "    ]\n",
    "\n",
    "    sm_train = []\n",
    "    sm_val = []\n",
    "    sm_test = []\n",
    "\n",
    "    small_train = pd.DataFrame()\n",
    "    small_val = pd.DataFrame()\n",
    "    small_test = pd.DataFrame()\n",
    "\n",
    "    random_state = 123\n",
    "    percent = .2\n",
    "\n",
    "    for category in response_categories:\n",
    "        sm_train.append(int(round(len(train[train.response == category]) * percent, 0)))\n",
    "        sm_val.append(int(round(len(validate[validate.response == category]) * percent, 0)))\n",
    "        sm_test.append(int(round(len(test[test.response == category]) * percent, 0)))\n",
    "        \n",
    "        small_train = small_train.append(train[train.response == category].sample(sm_train[-1], random_state=random_state))\n",
    "        small_val = small_val.append(validate[validate.response == category].sample(sm_val[-1], random_state=random_state))\n",
    "        small_test = small_test.append(test[test.response == category].sample(sm_test[-1], random_state=random_state))\n",
    "\n",
    "    small_train.reset_index(drop=True, inplace=True)\n",
    "    small_val.reset_index(drop=True, inplace=True)\n",
    "    small_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    X_train = encode(small_train)\n",
    "    X_train = X_train.drop(columns=['date_received','state','company_name','tags','product_bins', 'response'])\n",
    "    y_train = small_train['response']\n",
    "    X_val = encode(small_val)\n",
    "    X_val = X_val.drop(columns=['date_received','state','company_name','tags','product_bins', 'response'])\n",
    "    y_val = small_val['response']\n",
    "    X_test = encode(small_test)\n",
    "    X_test = X_test.drop(columns=['date_received','state','company_name','tags','product_bins', 'response'])\n",
    "    y_test = small_test['response']\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, etc...\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = process_data_modeling(train, val, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mbt_tfidf(Xtr,Xv,Xt,max_f=2900):\n",
    "    \"\"\"\n",
    "    The function `make_tfidf` takes in three sets of data (train, validation, and test) and applies the\n",
    "    TF-IDF vectorization technique to convert the text data into numerical features, using n-grams up to\n",
    "    trigrams and keeping single characters. It then returns the transformed data as pandas DataFrames.\n",
    "    \n",
    "    :param Xtr: Xtr is the training data, which is a dataframe containing the text data that you want to\n",
    "    transform into TF-IDF features. The \"lemmatized\" column in the dataframe contains the preprocessed\n",
    "    text data\n",
    "    :param Xv: Xv is the validation dataset, which is used to evaluate the performance of the model\n",
    "    during training\n",
    "    :param Xt: Xt is the input data for the test set. It is a dataframe containing the text data that\n",
    "    needs to be transformed into TF-IDF representation\n",
    "    :return: three dataframes: Xtr_tfidf, Xv_tfidf, and Xt_tfidf.\n",
    "    \"\"\"\n",
    "    #make my bag of words up to trigrams tfidf and keep single characters\n",
    "    tfidf = TfidfVectorizer(token_pattern=r'(?u)\\b\\w+\\b',lowercase=False, max_features=max_f, ngram_range=(1,3))\n",
    "    # fit and transform train\n",
    "    Xtr_bow_tfidf = tfidf.fit_transform(Xtr.lemon.astype(str))\n",
    "    # transform val and test\n",
    "    Xv_bow_tfidf = tfidf.transform(Xv.lemon.astype(str))\n",
    "    Xt_bow_tfidf = tfidf.transform(Xt.lemon.astype(str))\n",
    "    # make dfs\n",
    "    Xtr_tfidf = pd.DataFrame(Xtr_bow_tfidf.todense(),columns=tfidf.get_feature_names_out(),index=Xtr.index)\n",
    "    Xv_tfidf = pd.DataFrame(Xv_bow_tfidf.todense(),columns=tfidf.get_feature_names_out(),index=Xv.index)\n",
    "    Xt_tfidf = pd.DataFrame(Xt_bow_tfidf.todense(),columns=tfidf.get_feature_names_out(),index=Xt.index)\n",
    "    return Xtr_tfidf,Xv_tfidf,Xt_tfidf\n",
    "\n",
    "def process_vector_merge(X_train,X_val,X_test,max_f=2900):\n",
    "    X_train_tf, X_val_tf, X_test_tf = make_mbt_tfidf(X_train[['lemon']], X_val[['lemon']], X_test[['lemon']],max_f)\n",
    "    \n",
    "    encoded_train = X_train.iloc[:, 1:]\n",
    "    encoded_val = X_val.iloc[:, 1:]\n",
    "    encoded_test = X_test.iloc[:, 1:]\n",
    "    \n",
    "    X_train_tfe = encoded_train.merge(X_train_tf, left_index=True, right_index=True)\n",
    "    X_val_tfe = encoded_val.merge(X_val_tf, left_index=True, right_index=True)\n",
    "    X_test_tfe = encoded_test.merge(X_test_tf, left_index=True, right_index=True)\n",
    "    \n",
    "    # Visualization of train data\n",
    "    return X_train_tfe, X_val_tfe, X_test_tfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Older American</th>\n",
       "      <th>Older American, Servicemember</th>\n",
       "      <th>Servicemember</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>credit_report</th>\n",
       "      <th>debt_collection</th>\n",
       "      <th>loans</th>\n",
       "      <th>money_service</th>\n",
       "      <th>mortgage_x</th>\n",
       "      <th>ability</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>year old</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yet feel</th>\n",
       "      <th>yet feel like</th>\n",
       "      <th>yet receive</th>\n",
       "      <th>yet still</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.384389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148620</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148621</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148622</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148623</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148624</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148625 rows × 2909 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Older American  Older American, Servicemember  Servicemember  \\\n",
       "0                    0                              0              0   \n",
       "1                    0                              0              1   \n",
       "2                    0                              0              0   \n",
       "3                    0                              0              0   \n",
       "4                    0                              0              0   \n",
       "...                ...                            ...            ...   \n",
       "148620               0                              0              0   \n",
       "148621               0                              0              0   \n",
       "148622               0                              0              1   \n",
       "148623               0                              0              0   \n",
       "148624               0                              0              0   \n",
       "\n",
       "        credit_card  credit_report  debt_collection  loans  money_service  \\\n",
       "0                 0              1                0      0              0   \n",
       "1                 0              1                0      0              0   \n",
       "2                 0              1                0      0              0   \n",
       "3                 0              1                0      0              0   \n",
       "4                 0              1                0      0              0   \n",
       "...             ...            ...              ...    ...            ...   \n",
       "148620            0              1                0      0              0   \n",
       "148621            0              1                0      0              0   \n",
       "148622            0              0                1      0              0   \n",
       "148623            0              1                0      0              0   \n",
       "148624            0              0                0      1              0   \n",
       "\n",
       "        mortgage_x  ability  ...      year  year old  yes  yesterday      yet  \\\n",
       "0                0      0.0  ...  0.000000       0.0  0.0        0.0  0.00000   \n",
       "1                0      0.0  ...  0.000000       0.0  0.0        0.0  0.00000   \n",
       "2                0      0.0  ...  0.110518       0.0  0.0        0.0  0.00000   \n",
       "3                0      0.0  ...  0.000000       0.0  0.0        0.0  0.00000   \n",
       "4                0      0.0  ...  0.000000       0.0  0.0        0.0  0.23154   \n",
       "...            ...      ...  ...       ...       ...  ...        ...      ...   \n",
       "148620           0      0.0  ...  0.000000       0.0  0.0        0.0  0.00000   \n",
       "148621           0      0.0  ...  0.000000       0.0  0.0        0.0  0.00000   \n",
       "148622           0      0.0  ...  0.000000       0.0  0.0        0.0  0.00000   \n",
       "148623           0      0.0  ...  0.054731       0.0  0.0        0.0  0.00000   \n",
       "148624           0      0.0  ...  0.000000       0.0  0.0        0.0  0.00000   \n",
       "\n",
       "        yet feel  yet feel like  yet receive  yet still  zero  \n",
       "0            0.0            0.0     0.000000        0.0   0.0  \n",
       "1            0.0            0.0     0.000000        0.0   0.0  \n",
       "2            0.0            0.0     0.000000        0.0   0.0  \n",
       "3            0.0            0.0     0.000000        0.0   0.0  \n",
       "4            0.0            0.0     0.384389        0.0   0.0  \n",
       "...          ...            ...          ...        ...   ...  \n",
       "148620       0.0            0.0     0.000000        0.0   0.0  \n",
       "148621       0.0            0.0     0.000000        0.0   0.0  \n",
       "148622       0.0            0.0     0.000000        0.0   0.0  \n",
       "148623       0.0            0.0     0.000000        0.0   0.0  \n",
       "148624       0.0            0.0     0.000000        0.0   0.0  \n",
       "\n",
       "[148625 rows x 2909 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize\n",
    "X_train_tfe, X_val_tfe, X_test_tfe = process_vector_merge(X_train,X_val,X_test)\n",
    "X_train_tfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_multigram_model(Xtr,ytr,Xv,yv):\n",
    "    # unique features and tfidf\n",
    "    # decision tree\n",
    "    tree = DecisionTreeClassifier(criterion='log_loss',max_depth=7,min_samples_leaf=15,max_features=None,random_state=123)\n",
    "    tree.fit(Xtr,ytr)\n",
    "    # predictions\n",
    "    y_pred_train = tree.predict(Xtr)\n",
    "    y_pred_val = tree.predict(Xv)\n",
    "    # recall score\n",
    "    tr_rec = recall_score(ytr, y_pred_train, pos_label='no_relief')\n",
    "    v_rec = recall_score(yv, y_pred_val, pos_label='no_relief')\n",
    "    # accuracies\n",
    "    ytr_acc = tree.score(Xtr,ytr)\n",
    "    yv_acc = tree.score(Xv,yv)\n",
    "    # print results\n",
    "    print('Decision Tree Unigrams, Bigrams, Trigrams')\n",
    "    print(f'Train Accuracy:      {round(ytr_acc,4)*100}%')\n",
    "    print(f'Validation Accuracy: {round(yv_acc,4)*100}%')\n",
    "    print(f'Train Recall:        {round(tr_rec,4)*100}%')\n",
    "    print(f'Validation Recall:   {round(v_rec,4)*100}%')\n",
    "\n",
    "def svc_multigram_model(Xtr,ytr,Xv,yv):\n",
    "    # unique features and tfidf\n",
    "    # Linear svc\n",
    "    sv = LinearSVC(penalty='l2',C=1,dual=False,random_state=123,max_iter=500)\n",
    "    sv.fit(Xtr,ytr)\n",
    "    # predictions\n",
    "    y_pred_train = sv.predict(Xtr)\n",
    "    y_pred_val = sv.predict(Xv)\n",
    "    # recall score\n",
    "    tr_rec = recall_score(ytr, y_pred_train, pos_label='no_relief')\n",
    "    v_rec = recall_score(yv, y_pred_val, pos_label='no_relief')\n",
    "    # accuracies\n",
    "    ytr_acc = sv.score(Xtr,ytr)\n",
    "    yv_acc = sv.score(Xv,yv)\n",
    "    # print results\n",
    "    print('Linear SVC Unigrams, Bigrams, Trigrams')\n",
    "    print(f'Train Accuracy:      {round(ytr_acc,4)*100}%')\n",
    "    print(f'Validation Accuracy: {round(yv_acc,4)*100}%')\n",
    "    print(f'Train Recall:        {round(tr_rec,4)*100}%')\n",
    "    print(f'Validation Recall:   {round(v_rec,4)*100}%')\n",
    "\n",
    "def mlp_multigram_model(Xtr,ytr,Xv,yv):\n",
    "    # unique features and tfidf\n",
    "    # mlp\n",
    "    ml = MLPClassifier(activation='relu',solver='adam',random_state=123,early_stopping=True)\n",
    "    ml.fit(Xtr,ytr)\n",
    "    # predictions\n",
    "    y_pred_train = ml.predict(Xtr)\n",
    "    y_pred_val = ml.predict(Xv)\n",
    "    # recall score\n",
    "    tr_rec = recall_score(ytr, y_pred_train, pos_label='no_relief')\n",
    "    v_rec = recall_score(yv, y_pred_val, pos_label='no_relief')\n",
    "    # accuracies\n",
    "    ytr_acc = ml.score(Xtr,ytr)\n",
    "    yv_acc = ml.score(Xv,yv)\n",
    "    # print results\n",
    "    print('Multi-Layer Perceptron Unigrams, Bigrams, Trigrams')\n",
    "    print(f'Train Accuracy:      {round(ytr_acc,4)*100}%')\n",
    "    print(f'Validation Accuracy: {round(yv_acc,4)*100}%')\n",
    "    print(f'Train Recall:        {round(tr_rec,4)*100}%')\n",
    "    print(f'Validation Recall:   {round(v_rec,4)*100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7931034482758621"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = y_train.value_counts(normalize=True)[0]\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_multigram_model(X_train_tfe,y_train,X_val_tfe,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_multigram_model(X_train_tfe,y_train,X_val_tfe,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp_multigram_model(X_train_tfe,y_train,X_val_tfe,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_acc\t    val_acc\t        train_recall    val_recall\n",
    "\n",
    "# Tree\tcriterion='log_loss',max_depth=7,min_samples_leaf=15,max_features=None,random_state=123\t\n",
    "# 0.7989100084\t0.7974445925\t0.9954273595\t0.9944008959\n",
    "\n",
    "# SVC\tpenalty='l2',C=1,dual=False,random_state=123,max_iter=500\n",
    "# 0.8007939445\t0.7976464414\t0.98326193\t    0.9813702535\n",
    "\n",
    "# MLP\tactivation='relu',solver='adam',random_state=123,early_stopping=True\n",
    "# 0.810079058\t0.8000484437\t0.9726150583\t0.966990736"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfe, X_val_tfe, X_test_tfe = process_vector_merge(X_train,X_val,X_test,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47%\n",
      "Validation Accuracy: 79.29%\n",
      "Train Recall:        99.29%\n",
      "Validation Recall:   99.18%\n"
     ]
    }
   ],
   "source": [
    "tree_multigram_model(X_train_tfe,y_train,X_val_tfe,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "max_features=1000\n",
      "Decision Tree Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47%\n",
      "Validation Accuracy: 79.25%\n",
      "Train Recall:        99.21%\n",
      "Validation Recall:   99.09%\n",
      "Linear SVC Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.43%\n",
      "Validation Accuracy: 79.38%\n",
      "Train Recall:        99.35000000000001%\n",
      "Validation Recall:   99.31%\n",
      "Multi-Layer Perceptron Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.91%\n",
      "Validation Accuracy: 79.44%\n",
      "Train Recall:        97.65%\n",
      "Validation Recall:   97.38%\n",
      "---\n",
      "max_features=1100\n",
      "Decision Tree Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47%\n",
      "Validation Accuracy: 79.24%\n",
      "Train Recall:        99.22%\n",
      "Validation Recall:   99.08%\n",
      "Linear SVC Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.42%\n",
      "Validation Accuracy: 79.38%\n",
      "Train Recall:        99.31%\n",
      "Validation Recall:   99.29%\n",
      "Multi-Layer Perceptron Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.5%\n",
      "Validation Accuracy: 79.47%\n",
      "Train Recall:        99.44%\n",
      "Validation Recall:   99.42%\n",
      "---\n",
      "max_features=1200\n",
      "Decision Tree Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47999999999999%\n",
      "Validation Accuracy: 79.23%\n",
      "Train Recall:        99.19%\n",
      "Validation Recall:   99.03999999999999%\n",
      "Linear SVC Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.44%\n",
      "Validation Accuracy: 79.39%\n",
      "Train Recall:        99.27%\n",
      "Validation Recall:   99.25%\n",
      "Multi-Layer Perceptron Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.59%\n",
      "Validation Accuracy: 79.52%\n",
      "Train Recall:        99.18%\n",
      "Validation Recall:   99.14%\n",
      "---\n",
      "max_features=1300\n",
      "Decision Tree Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47%\n",
      "Validation Accuracy: 79.25%\n",
      "Train Recall:        99.2%\n",
      "Validation Recall:   99.07000000000001%\n",
      "Linear SVC Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.46%\n",
      "Validation Accuracy: 79.39%\n",
      "Train Recall:        99.24%\n",
      "Validation Recall:   99.22%\n",
      "Multi-Layer Perceptron Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.62%\n",
      "Validation Accuracy: 79.53%\n",
      "Train Recall:        98.81%\n",
      "Validation Recall:   98.74000000000001%\n",
      "---\n",
      "max_features=1400\n",
      "Decision Tree Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47999999999999%\n",
      "Validation Accuracy: 79.21000000000001%\n",
      "Train Recall:        99.18%\n",
      "Validation Recall:   99.02%\n",
      "Linear SVC Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47999999999999%\n",
      "Validation Accuracy: 79.36999999999999%\n",
      "Train Recall:        99.22%\n",
      "Validation Recall:   99.17%\n",
      "Multi-Layer Perceptron Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.69000000000001%\n",
      "Validation Accuracy: 79.52%\n",
      "Train Recall:        98.75%\n",
      "Validation Recall:   98.66%\n",
      "---\n",
      "max_features=1500\n",
      "Decision Tree Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47999999999999%\n",
      "Validation Accuracy: 79.25999999999999%\n",
      "Train Recall:        99.19%\n",
      "Validation Recall:   99.06%\n",
      "Linear SVC Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47999999999999%\n",
      "Validation Accuracy: 79.36%\n",
      "Train Recall:        99.2%\n",
      "Validation Recall:   99.09%\n",
      "Multi-Layer Perceptron Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      80.02%\n",
      "Validation Accuracy: 79.52%\n",
      "Train Recall:        98.41%\n",
      "Validation Recall:   98.16%\n",
      "---\n",
      "max_features=1600\n",
      "Decision Tree Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47%\n",
      "Validation Accuracy: 79.25999999999999%\n",
      "Train Recall:        99.15%\n",
      "Validation Recall:   99.03%\n",
      "Linear SVC Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47999999999999%\n",
      "Validation Accuracy: 79.38%\n",
      "Train Recall:        99.18%\n",
      "Validation Recall:   99.09%\n",
      "Multi-Layer Perceptron Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.62%\n",
      "Validation Accuracy: 79.58%\n",
      "Train Recall:        99.16%\n",
      "Validation Recall:   99.11999999999999%\n",
      "---\n",
      "max_features=1700\n",
      "Decision Tree Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47999999999999%\n",
      "Validation Accuracy: 79.29%\n",
      "Train Recall:        99.21%\n",
      "Validation Recall:   99.09%\n",
      "Linear SVC Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.5%\n",
      "Validation Accuracy: 79.36%\n",
      "Train Recall:        99.16%\n",
      "Validation Recall:   99.03%\n",
      "Multi-Layer Perceptron Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      80.13%\n",
      "Validation Accuracy: 79.54%\n",
      "Train Recall:        98.65%\n",
      "Validation Recall:   98.35000000000001%\n",
      "---\n",
      "max_features=1800\n",
      "Decision Tree Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47%\n",
      "Validation Accuracy: 79.29%\n",
      "Train Recall:        99.2%\n",
      "Validation Recall:   99.09%\n",
      "Linear SVC Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.51%\n",
      "Validation Accuracy: 79.36999999999999%\n",
      "Train Recall:        99.14%\n",
      "Validation Recall:   99.00999999999999%\n",
      "Multi-Layer Perceptron Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.61%\n",
      "Validation Accuracy: 79.46%\n",
      "Train Recall:        99.38%\n",
      "Validation Recall:   99.28%\n",
      "---\n",
      "max_features=1900\n",
      "Decision Tree Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47999999999999%\n",
      "Validation Accuracy: 79.28%\n",
      "Train Recall:        99.21%\n",
      "Validation Recall:   99.1%\n",
      "Linear SVC Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.53%\n",
      "Validation Accuracy: 79.36%\n",
      "Train Recall:        99.11999999999999%\n",
      "Validation Recall:   98.99%\n",
      "Multi-Layer Perceptron Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      80.46%\n",
      "Validation Accuracy: 79.49000000000001%\n",
      "Train Recall:        98.45%\n",
      "Validation Recall:   97.91%\n",
      "---\n",
      "max_features=2000\n",
      "Decision Tree Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47%\n",
      "Validation Accuracy: 79.29%\n",
      "Train Recall:        99.22%\n",
      "Validation Recall:   99.11999999999999%\n",
      "Linear SVC Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.56%\n",
      "Validation Accuracy: 79.33%\n",
      "Train Recall:        99.09%\n",
      "Validation Recall:   98.95%\n",
      "Multi-Layer Perceptron Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      80.47999999999999%\n",
      "Validation Accuracy: 79.53%\n",
      "Train Recall:        97.59%\n",
      "Validation Recall:   97.09%\n",
      "---\n",
      "max_features=2100\n",
      "Decision Tree Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47%\n",
      "Validation Accuracy: 79.29%\n",
      "Train Recall:        99.22%\n",
      "Validation Recall:   99.11%\n",
      "Linear SVC Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.56%\n",
      "Validation Accuracy: 79.34%\n",
      "Train Recall:        99.06%\n",
      "Validation Recall:   98.92%\n",
      "Multi-Layer Perceptron Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      80.30000000000001%\n",
      "Validation Accuracy: 79.5%\n",
      "Train Recall:        98.32%\n",
      "Validation Recall:   97.84%\n",
      "---\n",
      "max_features=2200\n",
      "Decision Tree Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47%\n",
      "Validation Accuracy: 79.29%\n",
      "Train Recall:        99.21%\n",
      "Validation Recall:   99.11%\n",
      "Linear SVC Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.55%\n",
      "Validation Accuracy: 79.34%\n",
      "Train Recall:        99.03%\n",
      "Validation Recall:   98.86%\n",
      "Multi-Layer Perceptron Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47%\n",
      "Validation Accuracy: 79.38%\n",
      "Train Recall:        99.66000000000001%\n",
      "Validation Recall:   99.63%\n",
      "---\n",
      "max_features=2300\n",
      "Decision Tree Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47%\n",
      "Validation Accuracy: 79.28%\n",
      "Train Recall:        99.21%\n",
      "Validation Recall:   99.11%\n",
      "Linear SVC Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.56%\n",
      "Validation Accuracy: 79.33%\n",
      "Train Recall:        99.00999999999999%\n",
      "Validation Recall:   98.82%\n",
      "Multi-Layer Perceptron Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.51%\n",
      "Validation Accuracy: 79.46%\n",
      "Train Recall:        99.27%\n",
      "Validation Recall:   99.22999999999999%\n",
      "---\n",
      "max_features=2400\n",
      "Decision Tree Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47%\n",
      "Validation Accuracy: 79.29%\n",
      "Train Recall:        99.21%\n",
      "Validation Recall:   99.11%\n",
      "Linear SVC Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.56%\n",
      "Validation Accuracy: 79.36999999999999%\n",
      "Train Recall:        99.00999999999999%\n",
      "Validation Recall:   98.83%\n",
      "Multi-Layer Perceptron Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.55%\n",
      "Validation Accuracy: 79.49000000000001%\n",
      "Train Recall:        99.38%\n",
      "Validation Recall:   99.33%\n",
      "---\n",
      "max_features=2500\n",
      "Decision Tree Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47999999999999%\n",
      "Validation Accuracy: 79.28%\n",
      "Train Recall:        99.21%\n",
      "Validation Recall:   99.1%\n",
      "Linear SVC Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.57%\n",
      "Validation Accuracy: 79.38%\n",
      "Train Recall:        98.99%\n",
      "Validation Recall:   98.83%\n",
      "Multi-Layer Perceptron Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.86%\n",
      "Validation Accuracy: 79.56%\n",
      "Train Recall:        98.79%\n",
      "Validation Recall:   98.68%\n",
      "---\n",
      "max_features=2600\n",
      "Decision Tree Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47999999999999%\n",
      "Validation Accuracy: 79.29%\n",
      "Train Recall:        99.21%\n",
      "Validation Recall:   99.11%\n",
      "Linear SVC Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.58%\n",
      "Validation Accuracy: 79.36999999999999%\n",
      "Train Recall:        98.99%\n",
      "Validation Recall:   98.81%\n",
      "Multi-Layer Perceptron Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.62%\n",
      "Validation Accuracy: 79.44%\n",
      "Train Recall:        99.16%\n",
      "Validation Recall:   99.05000000000001%\n",
      "---\n",
      "max_features=2700\n",
      "Decision Tree Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47999999999999%\n",
      "Validation Accuracy: 79.27%\n",
      "Train Recall:        99.22%\n",
      "Validation Recall:   99.11999999999999%\n",
      "Linear SVC Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.59%\n",
      "Validation Accuracy: 79.36999999999999%\n",
      "Train Recall:        98.95%\n",
      "Validation Recall:   98.78%\n",
      "Multi-Layer Perceptron Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      80.23%\n",
      "Validation Accuracy: 79.55%\n",
      "Train Recall:        98.65%\n",
      "Validation Recall:   98.24000000000001%\n",
      "---\n",
      "max_features=2800\n",
      "Decision Tree Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47%\n",
      "Validation Accuracy: 79.3%\n",
      "Train Recall:        99.22999999999999%\n",
      "Validation Recall:   99.15%\n",
      "Linear SVC Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.61%\n",
      "Validation Accuracy: 79.38%\n",
      "Train Recall:        98.92%\n",
      "Validation Recall:   98.76%\n",
      "Multi-Layer Perceptron Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      80.03%\n",
      "Validation Accuracy: 79.61%\n",
      "Train Recall:        98.5%\n",
      "Validation Recall:   98.32%\n",
      "---\n",
      "max_features=2900\n",
      "Decision Tree Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.47%\n",
      "Validation Accuracy: 79.3%\n",
      "Train Recall:        99.21%\n",
      "Validation Recall:   99.15%\n",
      "Linear SVC Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      79.61%\n",
      "Validation Accuracy: 79.39%\n",
      "Train Recall:        98.92%\n",
      "Validation Recall:   98.76%\n",
      "Multi-Layer Perceptron Unigrams, Bigrams, Trigrams\n",
      "Train Accuracy:      80.05%\n",
      "Validation Accuracy: 79.59%\n",
      "Train Recall:        98.36%\n",
      "Validation Recall:   98.13%\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(1000,3000,100):\n",
    "    print('---')\n",
    "    X_train_tfe, X_val_tfe, X_test_tfe = process_vector_merge(X_train,X_val,X_test,i)\n",
    "    print(f'max_features={i}')\n",
    "    tree_multigram_model(X_train_tfe,y_train,X_val_tfe,y_val)\n",
    "    svc_multigram_model(X_train_tfe,y_train,X_val_tfe,y_val)\n",
    "    mlp_multigram_model(X_train_tfe,y_train,X_val_tfe,y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
