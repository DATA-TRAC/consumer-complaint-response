{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dcc3ac-994e-47fb-b384-861002c33622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f84e2c4-2612-424e-aafb-949ba3d877d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports loaded successfully, awaiting commands...\n"
     ]
    }
   ],
   "source": [
    "#my modules\n",
    "import wrangle as wr\n",
    "import explore as ex\n",
    "import model as m\n",
    "\n",
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "# nltk.download('words')\n",
    "# words = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb829f8-69e1-406e-9596-4afd80d9a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef7b0fb9-f84b-4de2-ae57-66bda4349d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('cfpb_prep.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc11c8cf-835d-4216-b601-7e0e255bbb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Closed with explanation            982289\n",
       "Closed with non-monetary relief    205284\n",
       "Closed with monetary relief         50963\n",
       "Untimely response                    4459\n",
       "Closed                               3741\n",
       "Name: company_response_to_consumer, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.company_response_to_consumer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4121d2c5-e096-42ea-96aa-b95358cf9145",
   "metadata": {},
   "outputs": [],
   "source": [
    "relief = ['Closed with monetary relief', 'Closed with non-monetary relief']\n",
    "no_relief = ['Closed with explanation']\n",
    "df = df[df['company_response_to_consumer'] != \"Untimely response\"]\n",
    "df = df[df['company_response_to_consumer'] != \"Closed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "463d8b57-ea93-4a52-bdc5-ac053b2a334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['response'] = np.where(df['company_response_to_consumer'].isin(relief),'relief','')\n",
    "df['response'] = np.where(df['company_response_to_consumer'].isin(no_relief),'no_relief',df['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd10b564-d63b-4053-a9b9-c899952c3518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='company_response_to_consumer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07c4b7e2-6667-4b42-9286-6f524045d289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_relief    0.793105\n",
       "relief       0.206895\n",
       "Name: response, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.response.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1290b1e2-8a92-42d0-acec-0e806d6f6d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_relief    982289\n",
       "relief       256247\n",
       "Name: response, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.response.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48057a5-0e0d-45dd-9409-eb1355b934c9",
   "metadata": {},
   "source": [
    "Specificity: When the actual value is negative, how often is the prediction correct?\n",
    "\n",
    "* Something we want to maximize\n",
    "* How \"specific\" (or \"selective\") is the classifier in predicting positive instances?\n",
    "* TN / all negative\n",
    "    * all negative = TN + FP\n",
    "    \n",
    "False Positive Rate: When the actual value is negative, how often is the prediction incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22109af5-e792-41f5-95c4-6762eb24f7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared DF: (1238536, 8)\n",
      "Train: (743121, 8)\n",
      "Validate: (247707, 8)\n",
      "Test: (247708, 8)\n"
     ]
    }
   ],
   "source": [
    "# split\n",
    "train, val, test = wr.split_data(df, 'response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1401ad98-ddf2-4b0a-a68c-c43a7e53b2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_received</th>\n",
       "      <th>company_name</th>\n",
       "      <th>state</th>\n",
       "      <th>tags</th>\n",
       "      <th>product_bins</th>\n",
       "      <th>clean</th>\n",
       "      <th>lemon</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>274292</th>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>Experian Information Solutions Inc.</td>\n",
       "      <td>FL</td>\n",
       "      <td>Servicemember</td>\n",
       "      <td>credit_report</td>\n",
       "      <td>i have been a victim of id theft and have submitted documentation to the credit bureaus and they are refusing to abide by fcra b pertaining to my request the original creditor has no proof other than statements and i have constantly refuted this ...</td>\n",
       "      <td>victim id theft submitted documentation credit bureau refusing abide fcra b pertaining request original creditor proof statement constantly refuted charge submitting proof id theft claim reporting complaint credit bureau consistent harm financial...</td>\n",
       "      <td>relief</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_received                         company_name state  \\\n",
       "274292    2019-09-09  Experian Information Solutions Inc.    FL   \n",
       "\n",
       "                 tags   product_bins  \\\n",
       "274292  Servicemember  credit_report   \n",
       "\n",
       "                                                                                                                                                                                                                                                            clean  \\\n",
       "274292  i have been a victim of id theft and have submitted documentation to the credit bureaus and they are refusing to abide by fcra b pertaining to my request the original creditor has no proof other than statements and i have constantly refuted this ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                            lemon  \\\n",
       "274292  victim id theft submitted documentation credit bureau refusing abide fcra b pertaining request original creditor proof statement constantly refuted charge submitting proof id theft claim reporting complaint credit bureau consistent harm financial...   \n",
       "\n",
       "       response  \n",
       "274292   relief  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05c5d725-f5bd-4b94-aeee-b34ed3604292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(df):\n",
    "    '''Encode categorical columns'''\n",
    "    # columns to encode\n",
    "    cols = ['tags','product_bins']\n",
    "    # encode the dummies\n",
    "    dummy = pd.get_dummies(df[cols],prefix='',prefix_sep='',drop_first=True)\n",
    "    # bring the dummies along\n",
    "    return pd.concat([df,dummy],axis=1)\n",
    "\n",
    "\n",
    "def process_data_modeling(train, validate, test):\n",
    "    \"\"\"\n",
    "    The function `process_data_modeling` reads data from parquet files, performs data sampling,\n",
    "    encoding, and splits the data into training, validation, and test sets.\n",
    "    \n",
    "    :param train: The `train` parameter is the training dataset, which is a pandas DataFrame containing\n",
    "    the data for training the model\n",
    "    :param validate: The `validate` parameter is a DataFrame that contains the validation data. It is\n",
    "    read from a parquet file named 'validate.parquet'\n",
    "    :param test: The `test` parameter is a DataFrame that contains the test data for your model. It is\n",
    "    read from a parquet file named 'test.parquet'\n",
    "    :return: six variables: X_train, y_train, X_val, y_val, X_test, and y_test.\n",
    "    \"\"\"\n",
    "    random_state = 123\n",
    "    response_categories = [\n",
    "        'relief',\n",
    "        'no_relief'\n",
    "    ]\n",
    "\n",
    "    sm_train = []\n",
    "    sm_val = []\n",
    "    sm_test = []\n",
    "\n",
    "    small_train = pd.DataFrame()\n",
    "    small_val = pd.DataFrame()\n",
    "    small_test = pd.DataFrame()\n",
    "\n",
    "    random_state = 123\n",
    "    percent = .2\n",
    "\n",
    "    for category in response_categories:\n",
    "        sm_train.append(int(round(len(train[train.response == category]) * percent, 0)))\n",
    "        sm_val.append(int(round(len(validate[validate.response == category]) * percent, 0)))\n",
    "        sm_test.append(int(round(len(test[test.response == category]) * percent, 0)))\n",
    "        \n",
    "        small_train = small_train.append(train[train.response == category].sample(sm_train[-1], random_state=random_state))\n",
    "        small_val = small_val.append(validate[validate.response == category].sample(sm_val[-1], random_state=random_state))\n",
    "        small_test = small_test.append(test[test.response == category].sample(sm_test[-1], random_state=random_state))\n",
    "\n",
    "    small_train.reset_index(drop=True, inplace=True)\n",
    "    small_val.reset_index(drop=True, inplace=True)\n",
    "    small_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    X_train = encode(small_train)\n",
    "    X_train = X_train.drop(columns=['date_received','clean','state','company_name','tags','product_bins', 'response'])\n",
    "    y_train = small_train['response']\n",
    "    X_val = encode(small_val)\n",
    "    X_val = X_val.drop(columns=['date_received','clean','state','company_name','tags','product_bins', 'response'])\n",
    "    y_val = small_val['response']\n",
    "    X_test = encode(small_test)\n",
    "    X_test = X_test.drop(columns=['date_received', 'clean','state','company_name','tags','product_bins', 'response'])\n",
    "    y_test = small_test['response']\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1ccd17e-1a3e-4d60-87e6-ce97640e7c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, etc...\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = process_data_modeling(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46773964-f173-43a7-8393-b0028c39aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, recall_score, average_precision_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d465e64-f252-44a1-b441-1efd6d09e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mbt_tfidf(Xtr,Xv,Xt):\n",
    "    \"\"\"\n",
    "    The function `make_tfidf` takes in three sets of data (train, validation, and test) and applies the\n",
    "    TF-IDF vectorization technique to convert the text data into numerical features, using n-grams up to\n",
    "    trigrams and keeping single characters. It then returns the transformed data as pandas DataFrames.\n",
    "    \n",
    "    :param Xtr: Xtr is the training data, which is a dataframe containing the text data that you want to\n",
    "    transform into TF-IDF features. The \"lemmatized\" column in the dataframe contains the preprocessed\n",
    "    text data\n",
    "    :param Xv: Xv is the validation dataset, which is used to evaluate the performance of the model\n",
    "    during training\n",
    "    :param Xt: Xt is the input data for the test set. It is a dataframe containing the text data that\n",
    "    needs to be transformed into TF-IDF representation\n",
    "    :return: three dataframes: Xtr_tfidf, Xv_tfidf, and Xt_tfidf.\n",
    "    \"\"\"\n",
    "    #make my bag of words up to trigrams tfidf and keep single characters\n",
    "    tfidf = TfidfVectorizer(token_pattern=r'(?u)\\b\\w+\\b',lowercase=False, max_features=10000, ngram_range=(1,3))\n",
    "    # fit and transform train\n",
    "    Xtr_bow_tfidf = tfidf.fit_transform(Xtr.lemon.astype(str))\n",
    "    # transform val and test\n",
    "    Xv_bow_tfidf = tfidf.transform(Xv.lemon.astype(str))\n",
    "    Xt_bow_tfidf = tfidf.transform(Xt.lemon.astype(str))\n",
    "    # make dfs\n",
    "    Xtr_tfidf = pd.DataFrame(Xtr_bow_tfidf.todense(),columns=tfidf.get_feature_names_out(),index=Xtr.index)\n",
    "    Xv_tfidf = pd.DataFrame(Xv_bow_tfidf.todense(),columns=tfidf.get_feature_names_out(),index=Xv.index)\n",
    "    Xt_tfidf = pd.DataFrame(Xt_bow_tfidf.todense(),columns=tfidf.get_feature_names_out(),index=Xt.index)\n",
    "    return Xtr_tfidf,Xv_tfidf,Xt_tfidf\n",
    "\n",
    "def process_vector_merge(X_train,X_val,X_test):\n",
    "    X_train_tf, X_val_tf, X_test_tf = make_mbt_tfidf(X_train[['lemon']], X_val[['lemon']], X_test[['lemon']])\n",
    "    \n",
    "    encoded_train = X_train.iloc[:, 1:]\n",
    "    encoded_val = X_val.iloc[:, 1:]\n",
    "    encoded_test = X_test.iloc[:, 1:]\n",
    "    \n",
    "    X_train_tfe = encoded_train.merge(X_train_tf, left_index=True, right_index=True)\n",
    "    X_val_tfe = encoded_val.merge(X_val_tf, left_index=True, right_index=True)\n",
    "    X_test_tfe = encoded_test.merge(X_test_tf, left_index=True, right_index=True)\n",
    "    \n",
    "    # Visualization of train data\n",
    "    return X_train_tfe, X_val_tfe, X_test_tfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0de48ff-b152-4cf2-8706-78c216b25650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize\n",
    "X_train_tfe, X_val_tfe, X_test_tfe = process_vector_merge(X_train,X_val,X_test)\n",
    "X_train_tfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3a55e5-9d69-40bc-8871-8b9edc528e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make\n",
    "dt = DecisionTreeClassifier(random_state=123, max_depth=9, max_leaf_nodes=11)\n",
    "\n",
    "# fit\n",
    "dt.fit(X_train_tfe, y_train)\n",
    "\n",
    "# use\n",
    "dt_train = dt.score(X_train_tfe, y_train)\n",
    "dt_val = dt.score(X_val_tfe, y_val)\n",
    "print(f\"Train Accuracy: {dt_train:.3}%\")\n",
    "print(f\"Validate Accuracy: {dt_val:.3}%\")\n",
    "\n",
    "#predict\n",
    "dt_pred_train = dt.predict(X_train_tfe)\n",
    "dt_pred_val = dt.predict(X_val_tfe)\n",
    "\n",
    "# recall score\n",
    "r_score_train = recall_score(y_train, dt_pred_train, pos_label='no_relief')\n",
    "r_score_val = recall_score(y_val, dt_pred_val, pos_label='no_relief')\n",
    "print(f\"Train recall score: {r_score_train:.3}%\")\n",
    "print(f\"Validate recall score: {r_score_val:.3}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11c34df-e309-413c-a6bf-fcfacd1d27e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classification report for train\n",
    "pd.DataFrame(classification_report(y_train, dt_pred_train, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c172f4e2-18aa-4e7d-884d-e3e0f0ea881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classification report for validate\n",
    "pd.DataFrame(classification_report(y_val, dt_pred_val, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb25d7c-7c92-4148-ae97-bf86c09c5508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make\n",
    "dt = DecisionTreeClassifier(random_state=123, max_depth=25, max_leaf_nodes=30)\n",
    "\n",
    "# fit\n",
    "dt.fit(X_train_tfe, y_train)\n",
    "\n",
    "# use\n",
    "dt_train = dt.score(X_train_tfe, y_train)\n",
    "dt_val = dt.score(X_val_tfe, y_val)\n",
    "print(f\"Train Accuracy: {dt_train:.3}%\")\n",
    "print(f\"Validate Accuracy: {dt_val:.3}%\")\n",
    "\n",
    "#predict\n",
    "dt_pred_train = dt.predict(X_train_tfe)\n",
    "dt_pred_val = dt.predict(X_val_tfe)\n",
    "\n",
    "# recall score\n",
    "r_score_train = recall_score(y_train, dt_pred_train, pos_label='no_relief')\n",
    "r_score_val = recall_score(y_val, dt_pred_val, pos_label='no_relief')\n",
    "print(f\"Train recall score: {r_score_train:.3}%\")\n",
    "print(f\"Validate recall score: {r_score_val:.3}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cf23a8-1722-4fc5-9643-bf9acc337529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classification report for train\n",
    "pd.DataFrame(classification_report(y_train, dt_pred_train, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d8783e-f3a8-4dee-981a-d6789e3fcbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classification report for validate\n",
    "pd.DataFrame(classification_report(y_val, dt_pred_val, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7ba1e3-0c4e-402e-9353-8857368d5796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# plot \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99c56ad-52dd-434d-8c8a-fa219c7bb5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make\n",
    "lr = LogisticRegression(random_state=123)\n",
    "\n",
    "# fit model\n",
    "lr.fit(X_train_tfe, y_train)\n",
    "\n",
    "# use\n",
    "lr_train = lr.score(X_train_tfe, y_train)\n",
    "lr_val = lr.score(X_val_tfe, y_val)\n",
    "print(f\"Train Accuracy: {lr_train:.3}%\")\n",
    "print(f\"Validate Accuracy: {lr_val:.3}%\")\n",
    "\n",
    "# predictions\n",
    "y_pred_train = lr.predict(X_train_tfe)\n",
    "y_pred_val = lr.predict(X_val_tfe)\n",
    "\n",
    "# recall score\n",
    "r_score_train = recall_score(y_train, y_pred_train, pos_label='no_relief')\n",
    "r_score_val = recall_score(y_val, y_pred_val, pos_label='no_relief')\n",
    "print(f\"Train recall score: {r_score_train:.3}%\")\n",
    "print(f\"Validate recall score: {r_score_val:.3}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600c3b70-7112-4ab7-8ab6-331b47763b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report for train\n",
    "round(pd.DataFrame(classification_report(y_train, y_pred_train, output_dict=True)),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05609d8-df74-4f49-9837-f3e5d0b12bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report for validate\n",
    "round(pd.DataFrame(classification_report(y_val, y_pred_val, output_dict=True)),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb1056-5a9b-4fd6-ab9d-eff2d187b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_train, y_pred_train, labels=lr.classes_), display_labels=lr.classes_).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa84dbb-bbec-4d7d-b999-8693cdfe8b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish TN, TP, FP, FN\n",
    "TN = 4433\n",
    "TP = 115203\n",
    "FP = 2672\n",
    "FN = 26317"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327e0a2e-8cc0-402f-8921-0571a47b3fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specificity\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39ab1e2-f23c-40f3-b0cc-9aee7bb02f46",
   "metadata": {},
   "source": [
    "minimizing damage by looking at additional metrics on top of accuracy baseline which is an average. Slightly improved on baseline but where we really saw the benefit was looking at the recall score which states predicts relief - no relief given.\n",
    "\n",
    "98% good at catching false negatives. The times that isn't relieved results in 98% catch of this error which means, happier consumers, happier businesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b236d293-9da5-4b85-b767-c59d9ea7084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make\n",
    "lr = LogisticRegression(random_state=123)\n",
    "# fit model\n",
    "lr.fit(X_train_tfe, y_train)\n",
    "# use\n",
    "lr_train = lr.score(X_train_tfe, y_train)\n",
    "lr_val = lr.score(X_val_tfe, y_val)\n",
    "print(f\"Train Accuracy: {lr_train:.3}%\")\n",
    "print(f\"Validate Accuracy: {lr_val:.3}%\")\n",
    "# predictions\n",
    "y_pred_train = lr.predict(X_train_tfe)\n",
    "y_pred_val = lr.predict(X_val_tfe)\n",
    "# recall score\n",
    "r_score_train = recall_score(y_train, y_pred_train, pos_label='no_relief')\n",
    "r_score_val = recall_score(y_val, y_pred_val, pos_label='no_relief')\n",
    "print(f\"Train recall score: {r_score_train:.3}%\")\n",
    "print(f\"Validate recall score: {r_score_val:.3}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7bd4a0-1cea-49bb-bf98-c2767df09ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test\n",
    "\n",
    "# # use\n",
    "# lr_train = lr.score(X_train_tfe, y_train)\n",
    "# lr_val = lr.score(X_val_tfe, y_val)\n",
    "# print(f\"Train Accuracy: {lr_train:.3}%\")\n",
    "# print(f\"Validate Accuracy: {lr_val:.3}%\")\n",
    "\n",
    "# # predictions\n",
    "# y_pred_train = lr.predict(X_train_tfe)\n",
    "# y_pred_val = lr.predict(X_val_tfe)\n",
    "\n",
    "# # recall score\n",
    "# r_score_train = recall_score(y_train, y_pred_train, pos_label='no_relief')\n",
    "# r_score_val = recall_score(y_val, y_pred_val, pos_label='no_relief')\n",
    "# print(f\"Train recall score: {r_score_train:.3}%\")\n",
    "# print(f\"Validate recall score: {r_score_val:.3}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d050d555-269b-4f8e-a691-f4a74253e302",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_string_elements = X_train['lemon'].apply(lambda x: isinstance(x, str) == False)\n",
    "print(X_train[non_string_elements])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29b6fb68-4e97-4dbe-91fa-cb95fc19da8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['lemon'] = X_train['lemon'].fillna('')\n",
    "X_val['lemon'] = X_val['lemon'].fillna('')\n",
    "X_test['lemon'] = X_test['lemon'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32dbb937-d008-4982-85ba-583e4efb6d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['lemon'].values), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(list(X_val['lemon'].values), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(X_test['lemon'].values), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3651153a-acb7-40ae-b986-e2c0609f7909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6514, 0.4099, 0.7398],\n",
      "        [0.0962, 0.4834, 0.4572],\n",
      "        [0.8019, 0.7567, 0.4618],\n",
      "        [0.7222, 0.9518, 0.3475],\n",
      "        [0.2309, 0.5657, 0.3879]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "290ca4aa-82ec-458b-8948-db5c9b4d678a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m BertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Define the training arguments\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./results\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# output directory\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# total number of training epochs\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# batch size per device during training\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# batch size for evaluation\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# number of warmup steps for learning rate scheduler\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# strength of weight decay\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     16\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,               \u001b[38;5;66;03m# the instantiated ðŸ¤— Transformers model to be trained\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,        \u001b[38;5;66;03m# training arguments, defined above\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,  \u001b[38;5;66;03m# training dataset\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mval_dataset,   \u001b[38;5;66;03m# evaluation dataset\u001b[39;00m\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m<string>:112\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, no_cuda, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, gradient_checkpointing, include_inputs_for_metrics, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, xpu_backend)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/transformers/training_args.py:1372\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(version\u001b[38;5;241m.\u001b[39mparse(torch\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mbase_version) \u001b[38;5;241m==\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16:\n\u001b[1;32m   1367\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--optim adamw_torch_fused with --fp16 requires PyTorch>2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1370\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1371\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[0;32m-> 1372\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (get_xla_device_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16_full_eval)\n\u001b[1;32m   1375\u001b[0m ):\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1378\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (`--fp16_full_eval`) can only be used on CUDA devices.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1379\u001b[0m     )\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1388\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16_full_eval)\n\u001b[1;32m   1389\u001b[0m ):\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/transformers/training_args.py:1795\u001b[0m, in \u001b[0;36mTrainingArguments.device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1792\u001b[0m \u001b[38;5;124;03mThe device used by this process.\u001b[39;00m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1794\u001b[0m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m-> 1795\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_devices\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/transformers/utils/generic.py:54\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, obj, objtype)\u001b[0m\n\u001b[1;32m     52\u001b[0m cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/transformers/training_args.py:1716\u001b[0m, in \u001b[0;36mTrainingArguments._setup_devices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   1715\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available(min_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.20.1\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1716\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   1717\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1718\u001b[0m         )\n\u001b[1;32m   1719\u001b[0m     AcceleratorState\u001b[38;5;241m.\u001b[39m_reset_state(reset_partial_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',    # output directory\n",
    "    num_train_epochs=3,        # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,          # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,         # strength of weight decay\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,               # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,        # training arguments, defined above\n",
    "    train_dataset=train_dataset,  # training dataset\n",
    "    eval_dataset=val_dataset,   # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a56c833-f83e-4c8a-bdc3-a01d6895e69d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3194215581.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [18]\u001b[0;36m\u001b[0m\n\u001b[0;31m    ipip install transformers[torch]\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4496932f-7aba-49bc-ac57-3dbfbf74a7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22400ed8-fcf7-4ef5-85ae-8262c3931aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
