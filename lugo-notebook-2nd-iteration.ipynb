{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f84e2c4-2612-424e-aafb-949ba3d877d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports loaded successfully, awaiting commands...\n"
     ]
    }
   ],
   "source": [
    "#my modules\n",
    "import wrangle as wr\n",
    "import explore as ex\n",
    "import model as m\n",
    "\n",
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "# nltk.download('words')\n",
    "# words = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb829f8-69e1-406e-9596-4afd80d9a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef7b0fb9-f84b-4de2-ae57-66bda4349d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('cfpb_prep.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc11c8cf-835d-4216-b601-7e0e255bbb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Closed with explanation            982289\n",
       "Closed with non-monetary relief    205284\n",
       "Closed with monetary relief         50963\n",
       "Untimely response                    4459\n",
       "Closed                               3741\n",
       "Name: company_response_to_consumer, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.company_response_to_consumer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4121d2c5-e096-42ea-96aa-b95358cf9145",
   "metadata": {},
   "outputs": [],
   "source": [
    "relief = ['Closed with monetary relief', 'Closed with non-monetary relief']\n",
    "no_relief = ['Closed with explanation']\n",
    "df = df[df['company_response_to_consumer'] != \"Untimely response\"]\n",
    "df = df[df['company_response_to_consumer'] != \"Closed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "463d8b57-ea93-4a52-bdc5-ac053b2a334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['response'] = np.where(df['company_response_to_consumer'].isin(relief),'relief','')\n",
    "df['response'] = np.where(df['company_response_to_consumer'].isin(no_relief),'no_relief',df['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd10b564-d63b-4053-a9b9-c899952c3518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='company_response_to_consumer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07c4b7e2-6667-4b42-9286-6f524045d289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_relief    0.793105\n",
       "relief       0.206895\n",
       "Name: response, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.response.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1290b1e2-8a92-42d0-acec-0e806d6f6d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_relief    982289\n",
       "relief       256247\n",
       "Name: response, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.response.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48057a5-0e0d-45dd-9409-eb1355b934c9",
   "metadata": {},
   "source": [
    "Specificity: When the actual value is negative, how often is the prediction correct?\n",
    "\n",
    "* Something we want to maximize\n",
    "* How \"specific\" (or \"selective\") is the classifier in predicting positive instances?\n",
    "* TN / all negative\n",
    "    * all negative = TN + FP\n",
    "    \n",
    "False Positive Rate: When the actual value is negative, how often is the prediction incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22109af5-e792-41f5-95c4-6762eb24f7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared DF: (1238536, 8)\n",
      "Train: (743121, 8)\n",
      "Validate: (247707, 8)\n",
      "Test: (247708, 8)\n"
     ]
    }
   ],
   "source": [
    "# split\n",
    "train, val, test = wr.split_data(df, 'response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "856ad6a4-8ca2-42ae-9b60-10ba9cd2b8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_received  company_name  state  tags   product_bins  clean  lemon  response\n",
       "False          False         False  False  False         False  False  False       743093\n",
       "                                                         True   True   False           24\n",
       "                                                         False  True   False            4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1401ad98-ddf2-4b0a-a68c-c43a7e53b2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_received</th>\n",
       "      <th>company_name</th>\n",
       "      <th>state</th>\n",
       "      <th>tags</th>\n",
       "      <th>product_bins</th>\n",
       "      <th>clean</th>\n",
       "      <th>lemon</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>274292</th>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>Experian Information Solutions Inc.</td>\n",
       "      <td>FL</td>\n",
       "      <td>Servicemember</td>\n",
       "      <td>credit_report</td>\n",
       "      <td>i have been a victim of id theft and have submitted documentation to the credit bureaus and they are refusing to abide by fcra b pertaining to my request the original creditor has no proof other than statements and i have constantly refuted this ...</td>\n",
       "      <td>victim id theft submitted documentation credit bureau refusing abide fcra b pertaining request original creditor proof statement constantly refuted charge submitting proof id theft claim reporting complaint credit bureau consistent harm financial...</td>\n",
       "      <td>relief</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_received                         company_name state  \\\n",
       "274292    2019-09-09  Experian Information Solutions Inc.    FL   \n",
       "\n",
       "                 tags   product_bins  \\\n",
       "274292  Servicemember  credit_report   \n",
       "\n",
       "                                                                                                                                                                                                                                                            clean  \\\n",
       "274292  i have been a victim of id theft and have submitted documentation to the credit bureaus and they are refusing to abide by fcra b pertaining to my request the original creditor has no proof other than statements and i have constantly refuted this ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                            lemon  \\\n",
       "274292  victim id theft submitted documentation credit bureau refusing abide fcra b pertaining request original creditor proof statement constantly refuted charge submitting proof id theft claim reporting complaint credit bureau consistent harm financial...   \n",
       "\n",
       "       response  \n",
       "274292   relief  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05c5d725-f5bd-4b94-aeee-b34ed3604292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(df):\n",
    "    '''Encode categorical columns'''\n",
    "    # columns to encode\n",
    "    cols = ['tags','product_bins']\n",
    "    # encode the dummies\n",
    "    dummy = pd.get_dummies(df[cols],prefix='',prefix_sep='',drop_first=True)\n",
    "    # bring the dummies along\n",
    "    return pd.concat([df,dummy],axis=1)\n",
    "\n",
    "\n",
    "def process_data_modeling(train, validate, test):\n",
    "    \"\"\"\n",
    "    The function `process_data_modeling` reads data from parquet files, performs data sampling,\n",
    "    encoding, and splits the data into training, validation, and test sets.\n",
    "    \n",
    "    :param train: The `train` parameter is the training dataset, which is a pandas DataFrame containing\n",
    "    the data for training the model\n",
    "    :param validate: The `validate` parameter is a DataFrame that contains the validation data. It is\n",
    "    read from a parquet file named 'validate.parquet'\n",
    "    :param test: The `test` parameter is a DataFrame that contains the test data for your model. It is\n",
    "    read from a parquet file named 'test.parquet'\n",
    "    :return: six variables: X_train, y_train, X_val, y_val, X_test, and y_test.\n",
    "    \"\"\"\n",
    "    random_state = 123\n",
    "    response_categories = [\n",
    "        'relief',\n",
    "        'no_relief'\n",
    "    ]\n",
    "\n",
    "    sm_train = []\n",
    "    sm_val = []\n",
    "    sm_test = []\n",
    "\n",
    "    small_train = pd.DataFrame()\n",
    "    small_val = pd.DataFrame()\n",
    "    small_test = pd.DataFrame()\n",
    "\n",
    "    random_state = 123\n",
    "    percent = .2\n",
    "\n",
    "    for category in response_categories:\n",
    "        sm_train.append(int(round(len(train[train.response == category]) * percent, 0)))\n",
    "        sm_val.append(int(round(len(validate[validate.response == category]) * percent, 0)))\n",
    "        sm_test.append(int(round(len(test[test.response == category]) * percent, 0)))\n",
    "        \n",
    "        small_train = small_train.append(train[train.response == category].sample(sm_train[-1], random_state=random_state))\n",
    "        small_val = small_val.append(validate[validate.response == category].sample(sm_val[-1], random_state=random_state))\n",
    "        small_test = small_test.append(test[test.response == category].sample(sm_test[-1], random_state=random_state))\n",
    "\n",
    "    small_train.reset_index(drop=True, inplace=True)\n",
    "    small_val.reset_index(drop=True, inplace=True)\n",
    "    small_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    X_train = encode(small_train)\n",
    "    X_train = X_train.drop(columns=['date_received','clean','state','company_name','tags','product_bins', 'response'])\n",
    "    y_train = small_train['response']\n",
    "    X_val = encode(small_val)\n",
    "    X_val = X_val.drop(columns=['date_received','clean','state','company_name','tags','product_bins', 'response'])\n",
    "    y_val = small_val['response']\n",
    "    X_test = encode(small_test)\n",
    "    X_test = X_test.drop(columns=['date_received', 'clean','state','company_name','tags','product_bins', 'response'])\n",
    "    y_test = small_test['response']\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1ccd17e-1a3e-4d60-87e6-ce97640e7c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, etc...\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = process_data_modeling(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46773964-f173-43a7-8393-b0028c39aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, recall_score, average_precision_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d465e64-f252-44a1-b441-1efd6d09e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mbt_tfidf(Xtr,Xv,Xt):\n",
    "    \"\"\"\n",
    "    The function `make_tfidf` takes in three sets of data (train, validation, and test) and applies the\n",
    "    TF-IDF vectorization technique to convert the text data into numerical features, using n-grams up to\n",
    "    trigrams and keeping single characters. It then returns the transformed data as pandas DataFrames.\n",
    "    \n",
    "    :param Xtr: Xtr is the training data, which is a dataframe containing the text data that you want to\n",
    "    transform into TF-IDF features. The \"lemmatized\" column in the dataframe contains the preprocessed\n",
    "    text data\n",
    "    :param Xv: Xv is the validation dataset, which is used to evaluate the performance of the model\n",
    "    during training\n",
    "    :param Xt: Xt is the input data for the test set. It is a dataframe containing the text data that\n",
    "    needs to be transformed into TF-IDF representation\n",
    "    :return: three dataframes: Xtr_tfidf, Xv_tfidf, and Xt_tfidf.\n",
    "    \"\"\"\n",
    "    #make my bag of words up to trigrams tfidf and keep single characters\n",
    "    tfidf = TfidfVectorizer(token_pattern=r'(?u)\\b\\w+\\b',lowercase=False, max_features=10000, ngram_range=(1,3))\n",
    "    # fit and transform train\n",
    "    Xtr_bow_tfidf = tfidf.fit_transform(Xtr.lemon.astype(str))\n",
    "    # transform val and test\n",
    "    Xv_bow_tfidf = tfidf.transform(Xv.lemon.astype(str))\n",
    "    Xt_bow_tfidf = tfidf.transform(Xt.lemon.astype(str))\n",
    "    # make dfs\n",
    "    Xtr_tfidf = pd.DataFrame(Xtr_bow_tfidf.todense(),columns=tfidf.get_feature_names_out(),index=Xtr.index)\n",
    "    Xv_tfidf = pd.DataFrame(Xv_bow_tfidf.todense(),columns=tfidf.get_feature_names_out(),index=Xv.index)\n",
    "    Xt_tfidf = pd.DataFrame(Xt_bow_tfidf.todense(),columns=tfidf.get_feature_names_out(),index=Xt.index)\n",
    "    return Xtr_tfidf,Xv_tfidf,Xt_tfidf\n",
    "\n",
    "def process_vector_merge(X_train,X_val,X_test):\n",
    "    X_train_tf, X_val_tf, X_test_tf = make_mbt_tfidf(X_train[['lemon']], X_val[['lemon']], X_test[['lemon']])\n",
    "    \n",
    "    encoded_train = X_train.iloc[:, 1:]\n",
    "    encoded_val = X_val.iloc[:, 1:]\n",
    "    encoded_test = X_test.iloc[:, 1:]\n",
    "    \n",
    "    X_train_tfe = encoded_train.merge(X_train_tf, left_index=True, right_index=True)\n",
    "    X_val_tfe = encoded_val.merge(X_val_tf, left_index=True, right_index=True)\n",
    "    X_test_tfe = encoded_test.merge(X_test_tf, left_index=True, right_index=True)\n",
    "    \n",
    "    # Visualization of train data\n",
    "    return X_train_tfe, X_val_tfe, X_test_tfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0de48ff-b152-4cf2-8706-78c216b25650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize\n",
    "X_train_tfe, X_val_tfe, X_test_tfe = process_vector_merge(X_train,X_val,X_test)\n",
    "X_train_tfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3a55e5-9d69-40bc-8871-8b9edc528e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make\n",
    "dt = DecisionTreeClassifier(random_state=123, max_depth=9, max_leaf_nodes=11)\n",
    "\n",
    "# fit\n",
    "dt.fit(X_train_tfe, y_train)\n",
    "\n",
    "# use\n",
    "dt_train = dt.score(X_train_tfe, y_train)\n",
    "dt_val = dt.score(X_val_tfe, y_val)\n",
    "print(f\"Train Accuracy: {dt_train:.3}%\")\n",
    "print(f\"Validate Accuracy: {dt_val:.3}%\")\n",
    "\n",
    "#predict\n",
    "dt_pred_train = dt.predict(X_train_tfe)\n",
    "dt_pred_val = dt.predict(X_val_tfe)\n",
    "\n",
    "# recall score\n",
    "r_score_train = recall_score(y_train, dt_pred_train, pos_label='no_relief')\n",
    "r_score_val = recall_score(y_val, dt_pred_val, pos_label='no_relief')\n",
    "print(f\"Train recall score: {r_score_train:.3}%\")\n",
    "print(f\"Validate recall score: {r_score_val:.3}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11c34df-e309-413c-a6bf-fcfacd1d27e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classification report for train\n",
    "pd.DataFrame(classification_report(y_train, dt_pred_train, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c172f4e2-18aa-4e7d-884d-e3e0f0ea881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classification report for validate\n",
    "pd.DataFrame(classification_report(y_val, dt_pred_val, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb25d7c-7c92-4148-ae97-bf86c09c5508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make\n",
    "dt = DecisionTreeClassifier(random_state=123, max_depth=25, max_leaf_nodes=30)\n",
    "\n",
    "# fit\n",
    "dt.fit(X_train_tfe, y_train)\n",
    "\n",
    "# use\n",
    "dt_train = dt.score(X_train_tfe, y_train)\n",
    "dt_val = dt.score(X_val_tfe, y_val)\n",
    "print(f\"Train Accuracy: {dt_train:.3}%\")\n",
    "print(f\"Validate Accuracy: {dt_val:.3}%\")\n",
    "\n",
    "#predict\n",
    "dt_pred_train = dt.predict(X_train_tfe)\n",
    "dt_pred_val = dt.predict(X_val_tfe)\n",
    "\n",
    "# recall score\n",
    "r_score_train = recall_score(y_train, dt_pred_train, pos_label='no_relief')\n",
    "r_score_val = recall_score(y_val, dt_pred_val, pos_label='no_relief')\n",
    "print(f\"Train recall score: {r_score_train:.3}%\")\n",
    "print(f\"Validate recall score: {r_score_val:.3}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cf23a8-1722-4fc5-9643-bf9acc337529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classification report for train\n",
    "pd.DataFrame(classification_report(y_train, dt_pred_train, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d8783e-f3a8-4dee-981a-d6789e3fcbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classification report for validate\n",
    "pd.DataFrame(classification_report(y_val, dt_pred_val, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7ba1e3-0c4e-402e-9353-8857368d5796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# plot \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99c56ad-52dd-434d-8c8a-fa219c7bb5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make\n",
    "lr = LogisticRegression(random_state=123)\n",
    "\n",
    "# fit model\n",
    "lr.fit(X_train_tfe, y_train)\n",
    "\n",
    "# use\n",
    "lr_train = lr.score(X_train_tfe, y_train)\n",
    "lr_val = lr.score(X_val_tfe, y_val)\n",
    "print(f\"Train Accuracy: {lr_train:.3}%\")\n",
    "print(f\"Validate Accuracy: {lr_val:.3}%\")\n",
    "\n",
    "# predictions\n",
    "y_pred_train = lr.predict(X_train_tfe)\n",
    "y_pred_val = lr.predict(X_val_tfe)\n",
    "\n",
    "# recall score\n",
    "r_score_train = recall_score(y_train, y_pred_train, pos_label='no_relief')\n",
    "r_score_val = recall_score(y_val, y_pred_val, pos_label='no_relief')\n",
    "print(f\"Train recall score: {r_score_train:.3}%\")\n",
    "print(f\"Validate recall score: {r_score_val:.3}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600c3b70-7112-4ab7-8ab6-331b47763b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report for train\n",
    "round(pd.DataFrame(classification_report(y_train, y_pred_train, output_dict=True)),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05609d8-df74-4f49-9837-f3e5d0b12bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report for validate\n",
    "round(pd.DataFrame(classification_report(y_val, y_pred_val, output_dict=True)),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb1056-5a9b-4fd6-ab9d-eff2d187b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_train, y_pred_train, labels=lr.classes_), display_labels=lr.classes_).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa84dbb-bbec-4d7d-b999-8693cdfe8b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish TN, TP, FP, FN\n",
    "TN = 4433\n",
    "TP = 115203\n",
    "FP = 2672\n",
    "FN = 26317"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327e0a2e-8cc0-402f-8921-0571a47b3fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specificity\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39ab1e2-f23c-40f3-b0cc-9aee7bb02f46",
   "metadata": {},
   "source": [
    "minimizing damage by looking at additional metrics on top of accuracy baseline which is an average. Slightly improved on baseline but where we really saw the benefit was looking at the recall score which states predicts relief - no relief given.\n",
    "\n",
    "98% good at catching false negatives. The times that isn't relieved results in 98% catch of this error which means, happier consumers, happier businesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b236d293-9da5-4b85-b767-c59d9ea7084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make\n",
    "lr = LogisticRegression(random_state=123)\n",
    "# fit model\n",
    "lr.fit(X_train_tfe, y_train)\n",
    "# use\n",
    "lr_train = lr.score(X_train_tfe, y_train)\n",
    "lr_val = lr.score(X_val_tfe, y_val)\n",
    "print(f\"Train Accuracy: {lr_train:.3}%\")\n",
    "print(f\"Validate Accuracy: {lr_val:.3}%\")\n",
    "# predictions\n",
    "y_pred_train = lr.predict(X_train_tfe)\n",
    "y_pred_val = lr.predict(X_val_tfe)\n",
    "# recall score\n",
    "r_score_train = recall_score(y_train, y_pred_train, pos_label='no_relief')\n",
    "r_score_val = recall_score(y_val, y_pred_val, pos_label='no_relief')\n",
    "print(f\"Train recall score: {r_score_train:.3}%\")\n",
    "print(f\"Validate recall score: {r_score_val:.3}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7bd4a0-1cea-49bb-bf98-c2767df09ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test\n",
    "\n",
    "# # use\n",
    "# lr_train = lr.score(X_train_tfe, y_train)\n",
    "# lr_val = lr.score(X_val_tfe, y_val)\n",
    "# print(f\"Train Accuracy: {lr_train:.3}%\")\n",
    "# print(f\"Validate Accuracy: {lr_val:.3}%\")\n",
    "\n",
    "# # predictions\n",
    "# y_pred_train = lr.predict(X_train_tfe)\n",
    "# y_pred_val = lr.predict(X_val_tfe)\n",
    "\n",
    "# # recall score\n",
    "# r_score_train = recall_score(y_train, y_pred_train, pos_label='no_relief')\n",
    "# r_score_val = recall_score(y_val, y_pred_val, pos_label='no_relief')\n",
    "# print(f\"Train recall score: {r_score_train:.3}%\")\n",
    "# print(f\"Validate recall score: {r_score_val:.3}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d050d555-269b-4f8e-a691-f4a74253e302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       lemon  Older American  Older American, Servicemember  Servicemember  \\\n",
      "7137    None               0                              0              0   \n",
      "20876   None               0                              0              0   \n",
      "42286   None               0                              0              0   \n",
      "45663   None               0                              0              0   \n",
      "100459  None               0                              0              0   \n",
      "\n",
      "        credit_card  credit_report  debt_collection  loans  money_service  \\\n",
      "7137              0              1                0      0              0   \n",
      "20876             0              1                0      0              0   \n",
      "42286             0              0                1      0              0   \n",
      "45663             0              1                0      0              0   \n",
      "100459            0              1                0      0              0   \n",
      "\n",
      "        mortgage  \n",
      "7137           0  \n",
      "20876          0  \n",
      "42286          0  \n",
      "45663          0  \n",
      "100459         0  \n"
     ]
    }
   ],
   "source": [
    "non_string_elements = X_train['lemon'].apply(lambda x: isinstance(x, str) == False)\n",
    "print(X_train[non_string_elements])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b05b7a68-d8e4-4e20-8de3-5b7ae5efa6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lemon                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Older American  Older American, Servicemember  Servicemember  credit_card  credit_report  debt_collection  loans  money_service  mortgage\n",
       "accordance fair credit reporting act account violated right u c section state right privacy u c section section also state consumer reporting agency furnish account without written instruction                                                                                                                                                                                                                                                                                                                                                                                       0               0                              0              0            1              0                0      0              0           676\n",
       "accordance fair credit reporting act violated right u c section state right privacy u c section section also state consumer reporting agency furnish account without written instruction                                                                                                                                                                                                                                                                                                                                                                                               0               0                              0              0            1              0                0      0              0           299\n",
       "im really sure happened mailed letter credit bureau continuously thus far gotten response name filing complaint falsely reporting misleading information third party involved please review uploaded letter                                                                                                                                                                                                                                                                                                                                                                            0               0                              0              0            1              0                0      0              0           290\n",
       "name complaint made error neither made third party declare penalty perjury alleging person company without authorization unauthorized use social security number card used personal identifying information apply good service money successful creating account knowledge investigated ftc u code b permissible purpose consumer report never gave written consent report anything consumer report consent fraud                                                                                                                                                                      0               0                              0              0            1              0                0      0              0           222\n",
       "concerned item shown credit report inaccurate also unjust reporting credit report ask delete account filing legal complaint                                                                                                                                                                                                                                                                                                                                                                                                                                                            0               0                              0              0            1              0                0      0              0           195\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ... \n",
       "equiifax reporting inaccurate information show current collection account paid company agreed remove paid classified paid deletion account removed recent dispute company sure step took verifying account look like nt contact company checked see information matched record gross violation fcra called phone inform issue claim nt way verify account company agreed remove told contact company first question company know information accurate without communicating company directly many possible error take place federal right protected need account removed list account  0               0                              0              0            1              0                0      0              0             1\n",
       "equifaxs investigation debt dispute proof provide supporting documentation lawfully owe alleged debt                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   0               0                              0              0            1              0                0      0              0             1\n",
       "equifaxhas incorrect information delinquent bill creditor live date incorrect need removed also illegal put rental credit report covid time living owned house starting                                                                                                                                                                                                                                                                                                                                                                                                                0               0                              0              0            1              0                0      0              0             1\n",
       "equifaxcredit report totally helpful know anything told hard inquires die frozen triedfor year going frozen dont allow ny credit since moved score even messed u p let credit card close tried let card get rgit get credit freeze give hard inquierys b c credit freeze whole year today investigation made like fcra section even used thing wrong credit file score made card close letting use report see info like using card stuff licked                                                                                                                                        0               0                              1              0            1              0                0      0              0             1\n",
       "zwicker failed release judgement record case amount lessor judgement involves error reporting see attached                                                                                                                                                                                                                                                                                                                                                                                                                                                                             0               0                              0              0            0              1                0      0              0             1\n",
       "Length: 132132, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34f0cced-4a5c-400c-be40-cec61c9d49f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lemon  Older American  Older American, Servicemember  Servicemember  credit_card  credit_report  debt_collection  loans  money_service  mortgage\n",
       "False  False           False                          False          False        False          False            False  False          False       148620\n",
       "True   False           False                          False          False        False          False            False  False          False            5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32dbb937-d008-4982-85ba-583e4efb6d56",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer\n\u001b[1;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m train_encodings \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlemon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m val_encodings \u001b[38;5;241m=\u001b[39m tokenizer(\u001b[38;5;28mlist\u001b[39m(X_val[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlemon\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues), truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m test_encodings \u001b[38;5;241m=\u001b[39m tokenizer(\u001b[38;5;28mlist\u001b[39m(X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlemon\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues), truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2577\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2575\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2576\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2577\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2579\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2663\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2658\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2659\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2660\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2661\u001b[0m         )\n\u001b[1;32m   2662\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 2663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2664\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2665\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2667\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2680\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2681\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2682\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2683\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   2684\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   2685\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2701\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2702\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2854\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2844\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2845\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2846\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   2847\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2851\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2852\u001b[0m )\n\u001b[0;32m-> 2854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2856\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2867\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2868\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2869\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2871\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2872\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils.py:733\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     ids, pair_ids \u001b[38;5;241m=\u001b[39m ids_or_pair_ids\n\u001b[0;32m--> 733\u001b[0m first_ids \u001b[38;5;241m=\u001b[39m \u001b[43mget_input_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m second_ids \u001b[38;5;241m=\u001b[39m get_input_ids(pair_ids) \u001b[38;5;28;01mif\u001b[39;00m pair_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    735\u001b[0m input_ids\u001b[38;5;241m.\u001b[39mappend((first_ids, second_ids))\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils.py:713\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus.<locals>.get_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 713\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    714\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    715\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Input is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers."
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(list(X_train['lemon'].values), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(list(X_val['lemon'].values), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(X_test['lemon'].values), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290ca4aa-82ec-458b-8948-db5c9b4d678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',    # output directory\n",
    "    num_train_epochs=3,        # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,          # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,         # strength of weight decay\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,               # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,        # training arguments, defined above\n",
    "    train_dataset=X_train,  # training dataset\n",
    "    eval_dataset=X_val,   # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0659687-9182-4b49-8d7c-9a65588b667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizerFast, Trainer, TrainingArguments\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize and prepare the datasets for BERT\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
    "\n",
    "# Convert to PyTorch Datasets\n",
    "train_dataset = torch.utils.data.Dataset(train_encodings, train_labels)\n",
    "val_dataset = torch.utils.data.Dataset(val_encodings, val_labels)\n",
    "test_dataset = torch.utils.data.Dataset(test_encodings, test_labels)\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',  # output directory\n",
    "    num_train_epochs=3,  # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
    "    warmup_steps=500,  # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,  # strength of weight decay\n",
    "    logging_dir='./logs',  # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Create a trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3651153a-acb7-40ae-b986-e2c0609f7909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a56c833-f83e-4c8a-bdc3-a01d6895e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4496932f-7aba-49bc-ac57-3dbfbf74a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop=True)\n",
    "X_val = X_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22400ed8-fcf7-4ef5-85ae-8262c3931aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Then, you can use this class to create your datasets:\n",
    "train_dataset = CustomDataset(train_encodings, train_labels)\n",
    "val_dataset = CustomDataset(val_encodings, val_labels)\n",
    "\n",
    "# Now, you can pass these to the Trainer:\n",
    "trainer = Trainer(\n",
    "    model=model,               # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,        # training arguments, defined above\n",
    "    train_dataset=train_dataset,  # training dataset\n",
    "    eval_dataset=val_dataset,   # evaluation dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc43c14-c2cb-4aec-b8e4-7dd9513015ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acccafec-48d2-406b-9e24-076613b39638",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b6fb68-4e97-4dbe-91fa-cb95fc19da8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['lemon'] = X_train['lemon'].fillna('')\n",
    "X_val['lemon'] = X_val['lemon'].fillna('')\n",
    "X_test['lemon'] = X_test['lemon'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8545583-efb4-4344-93d9-869899dd8dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Define the features (X) and the target variable (y)\n",
    "X_train = train['lemon']\n",
    "y_train = train['response']\n",
    "X_test = test['lemon']\n",
    "y_test = test['response']\n",
    "\n",
    "\n",
    "X_train['lemon'] = X_train['lemon'].fillna('')\n",
    "X_val['lemon'] = X_val['lemon'].fillna('')\n",
    "X_test['lemon'] = X_test['lemon'].fillna('')\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_val = X_val.reset_index(drop=True)\n",
    "\n",
    "# Preprocess the text data (e.g., vectorize the text using CountVectorizer or TF-IDFVectorizer)\n",
    "\n",
    "# Create an instance of the Gradient Boosting Classifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Fit the model on the training data\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = gbc.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = gbc.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Perform hyperparameter tuning (optional)\n",
    "# You can use techniques like grid search or randomized search to find the optimal hyperparameters\n",
    "\n",
    "# Example of hyperparameter tuning using GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.1, 0.05, 0.01],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(gbc, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found during hyperparameter tuning\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Make predictions using the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the best model\n",
    "accuracy_best = best_model.score(X_test, y_test)\n",
    "print(\"Best Model Accuracy:\", accuracy_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37375b0f-0858-49b2-ab02-14117054b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create an instance of CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the training data\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the fitted vectorizer\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Create an instance of the Gradient Boosting Classifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Fit the model on the vectorized training data\n",
    "gbc.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Make predictions on the vectorized test data\n",
    "y_pred = gbc.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = gbc.score(X_test_vectorized, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6078b25-42d1-4f9c-82d8-abf87f27febd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Define the features (X) and the target variable (y)\n",
    "X_train = train['lemon']\n",
    "y_train = train['response']\n",
    "X_test = test['lemon']\n",
    "y_test = test['response']\n",
    "\n",
    "X_train = X_train.fillna('')\n",
    "X_test = X_test.fillna('')\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "\n",
    "# Preprocess the text data (e.g., vectorize the text using CountVectorizer or TF-IDFVectorizer)\n",
    "\n",
    "# Create an instance of the Gradient Boosting Classifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Fit the model on the training data\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = gbc.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = gbc.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Perform hyperparameter tuning (optional)\n",
    "# You can use techniques like grid search or randomized search to find the optimal hyperparameters\n",
    "\n",
    "# Example of hyperparameter tuning using GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.1, 0.05, 0.01],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(gbc, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found during hyperparameter tuning\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Make predictions using the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the best model\n",
    "accuracy_best = best_model.score(X_test, y_test)\n",
    "print(\"Best Model Accuracy:\", accuracy_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35fcda6-79a7-4de1-ac1b-3819165d8463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
