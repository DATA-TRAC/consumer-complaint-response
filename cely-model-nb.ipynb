{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports loaded successfully, awaiting commands...\n"
     ]
    }
   ],
   "source": [
    "import wrangle as w\n",
    "import model as m\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as stats\n",
    "import nltk\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet('train.parquet')\n",
    "validate = pd.read_parquet('validate.parquet')\n",
    "test = pd.read_parquet('test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemon</th>\n",
       "      <th>Older American</th>\n",
       "      <th>Older American, Servicemember</th>\n",
       "      <th>Servicemember</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>credit_report</th>\n",
       "      <th>debt_collection</th>\n",
       "      <th>loans</th>\n",
       "      <th>money_service</th>\n",
       "      <th>mortgage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48045</th>\n",
       "      <td>trying contact grain technology inc debt owed ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164880</th>\n",
       "      <td>bought large rug start vacation called filed d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463976</th>\n",
       "      <td>original complaint went car dealership ohio lo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490359</th>\n",
       "      <td>synopsis loan demand estate loan originated an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316427</th>\n",
       "      <td>may concern writing dispute fraudulent charge ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     lemon  Older American  \\\n",
       "48045    trying contact grain technology inc debt owed ...               0   \n",
       "1164880  bought large rug start vacation called filed d...               0   \n",
       "463976   original complaint went car dealership ohio lo...               0   \n",
       "490359   synopsis loan demand estate loan originated an...               0   \n",
       "316427   may concern writing dispute fraudulent charge ...               0   \n",
       "\n",
       "         Older American, Servicemember  Servicemember  credit_card  \\\n",
       "48045                                0              0            0   \n",
       "1164880                              0              0            1   \n",
       "463976                               0              0            0   \n",
       "490359                               0              0            0   \n",
       "316427                               0              0            0   \n",
       "\n",
       "         credit_report  debt_collection  loans  money_service  mortgage  \n",
       "48045                0                1      0              0         0  \n",
       "1164880              0                0      0              0         0  \n",
       "463976               1                0      0              0         0  \n",
       "490359               0                0      0              0         1  \n",
       "316427               1                0      0              0         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_train1 = int(round(len(train[train.company_response_to_consumer=='Closed with explanation'])*.2,0))\n",
    "sm_train2 = int(round(len(train[train.company_response_to_consumer=='Closed with non-monetary relief'])*.2,0))\n",
    "sm_train3 = int(round(len(train[train.company_response_to_consumer=='Closed with monetary relief'])*.2,0))\n",
    "sm_train4 = int(round(len(train[train.company_response_to_consumer=='Untimely response'])*.2,0))\n",
    "sm_train5 = int(round(len(train[train.company_response_to_consumer=='Closed'])*.2,0))\n",
    "sm_val1 = int(round(len(validate[validate.company_response_to_consumer=='Closed with explanation'])*.2,0))\n",
    "sm_val2 = int(round(len(validate[validate.company_response_to_consumer=='Closed with non-monetary relief'])*.2,0))\n",
    "sm_val3 = int(round(len(validate[validate.company_response_to_consumer=='Closed with monetary relief'])*.2,0))\n",
    "sm_val4 = int(round(len(validate[validate.company_response_to_consumer=='Untimely response'])*.2,0))\n",
    "sm_val5 = int(round(len(validate[validate.company_response_to_consumer=='Closed'])*.2,0))\n",
    "sm_test1 = int(round(len(test[test.company_response_to_consumer=='Closed with explanation'])*.2,0))\n",
    "sm_test2 = int(round(len(test[test.company_response_to_consumer=='Closed with non-monetary relief'])*.2,0))\n",
    "sm_test3 = int(round(len(test[test.company_response_to_consumer=='Closed with monetary relief'])*.2,0))\n",
    "sm_test4 = int(round(len(test[test.company_response_to_consumer=='Untimely response'])*.2,0))\n",
    "sm_test5 = int(round(len(test[test.company_response_to_consumer=='Closed'])*.2,0))\n",
    "\n",
    "small_train1 = train[train.company_response_to_consumer=='Closed with explanation'].sample(sm_train1,random_state=123)\n",
    "small_train2 = train[train.company_response_to_consumer=='Closed with non-monetary relief'].sample(sm_train2,random_state=123)\n",
    "small_train3 = train[train.company_response_to_consumer=='Closed with monetary relief'].sample(sm_train3,random_state=123)\n",
    "small_train4 = train[train.company_response_to_consumer=='Untimely response'].sample(sm_train4,random_state=123)\n",
    "small_train5 = train[train.company_response_to_consumer=='Closed'].sample(sm_train5,random_state=123)\n",
    "small_val1 = validate[validate.company_response_to_consumer=='Closed with explanation'].sample(sm_val1,random_state=123)\n",
    "small_val2 = validate[validate.company_response_to_consumer=='Closed with non-monetary relief'].sample(sm_val2,random_state=123)\n",
    "small_val3 = validate[validate.company_response_to_consumer=='Closed with monetary relief'].sample(sm_val3,random_state=123)\n",
    "small_val4 = validate[validate.company_response_to_consumer=='Untimely response'].sample(sm_val4,random_state=123)\n",
    "small_val5 = validate[validate.company_response_to_consumer=='Closed'].sample(sm_val5,random_state=123)\n",
    "small_test1 = test[test.company_response_to_consumer=='Closed with explanation'].sample(sm_test1,random_state=123)\n",
    "small_test2 = test[test.company_response_to_consumer=='Closed with non-monetary relief'].sample(sm_test2,random_state=123)\n",
    "small_test3 = test[test.company_response_to_consumer=='Closed with monetary relief'].sample(sm_test3,random_state=123)\n",
    "small_test4 = test[test.company_response_to_consumer=='Untimely response'].sample(sm_test4,random_state=123)\n",
    "small_test5 = test[test.company_response_to_consumer=='Closed'].sample(sm_test5,random_state=123)\n",
    "\n",
    "small_train = pd.concat([small_train1,small_train2,small_train3,small_train4,small_train5])\n",
    "small_val = pd.concat([small_val1,small_val2,small_val3,small_val4,small_val5])\n",
    "small_test = pd.concat([small_test1,small_test2,small_test3,small_test4,small_test5])\n",
    "\n",
    "X_train = m.encode(small_train)\n",
    "X_train = X_train.drop(columns=['date_received','company_response_to_consumer','clean','state','company_name','tags','product_bins'])\n",
    "y_train = small_train['company_response_to_consumer']\n",
    "X_val = m.encode(small_val)\n",
    "X_val = X_val.drop(columns=['date_received','company_response_to_consumer','clean','state','company_name','tags','product_bins'])\n",
    "y_val = small_val['company_response_to_consumer']\n",
    "X_test = m.encode(small_test)\n",
    "X_test = X_test.drop(columns=['date_received','company_response_to_consumer','clean','state','company_name','tags','product_bins'])\n",
    "y_test = small_test['company_response_to_consumer']\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf,X_val_tf,X_test_tf = m.make_tfidf(X_train, X_val, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = X_train.iloc[:,1:]\n",
    "encoded_val = X_val.iloc[:,1:]\n",
    "encoded_test = X_test.iloc[:,1:]\n",
    "\n",
    "\n",
    "\n",
    "X_train_tfe = encoded_train.merge(X_train_tf,left_index=True, right_index=True)\n",
    "X_val_tfe = encoded_val.merge(X_val_tf,left_index=True, right_index=True)\n",
    "X_test_tfe = encoded_test.merge(X_test_tf,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparams = [\n",
    "    {'max_depth': 5, 'learning_rate': 0.1, 'n_estimators': 15}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def xgboost_hyperparam_search(X_train, y_train, X_val, y_val, hyperparams):\n",
    "    results = []\n",
    "    \n",
    "    for params in hyperparams:\n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        train_pred = model.predict(X_train)\n",
    "        train_acc = accuracy_score(y_train, train_pred)\n",
    "        \n",
    "        val_pred = model.predict(X_val)\n",
    "        val_acc = accuracy_score(y_val, val_pred)\n",
    "        \n",
    "        results.append({'Parameters': params, 'Train Accuracy': train_acc, 'Validation Accuracy': val_acc})\n",
    "    \n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results = df_results.sort_values(by='Validation Accuracy', ascending=False).head(10)\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost_hyperparam_search(X_train_cve, y_train_encoded, X_val_cve, y_val_encoded, hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost_hyperparam_search(X_train_cve, y_train_encoded, X_val_cve, y_val_encoded, hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def train_lightgbm_model(x_train, y_train, x_val, y_val, hyperparams):\n",
    "    # Create LightGBM dataset\n",
    "    train_data = lgb.Dataset(x_train, label=y_train)\n",
    "    val_data = lgb.Dataset(x_val, label=y_val)\n",
    "\n",
    "    # Set hyperparameters\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': hyperparams['num_leaves'],\n",
    "        'learning_rate': hyperparams['learning_rate'],\n",
    "        'feature_fraction': hyperparams['feature_fraction'],\n",
    "        'bagging_fraction': hyperparams['bagging_fraction'],\n",
    "        'bagging_freq': hyperparams['bagging_freq'],\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "    # Train the model\n",
    "    model = lgb.train(params,\n",
    "                      train_data,\n",
    "                      valid_sets=[train_data, val_data],\n",
    "                      num_boost_round=hyperparams['num_boost_round'],\n",
    "                      early_stopping_rounds=hyperparams['early_stopping_rounds'],\n",
    "                      verbose_eval=hyperparams['verbose_eval'])\n",
    "\n",
    "    # Predict on validation data\n",
    "    y_pred = model.predict(x_val)\n",
    "\n",
    "    # Calculate AUC score\n",
    "    auc_score = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "    return model, auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_lightgbm_model(x_train, y_train, x_val, y_val, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def run_decision_tree_classifier(X_train, y_train, X_val, y_val, **kwargs):\n",
    "    # Initialize the decision tree classifier with hyperparameters\n",
    "    classifier = DecisionTreeClassifier(**kwargs)\n",
    "    \n",
    "    # Train the classifier\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_pred = classifier.predict(X_val)\n",
    "    \n",
    "    # Calculate the accuracy of the classifier\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    \n",
    "    # Create a dataframe to hold the results\n",
    "    results = pd.DataFrame({\n",
    "        'Actual': y_val,\n",
    "        'Predicted': y_pred\n",
    "    })\n",
    "    \n",
    "    # Print the accuracy\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    # Return the results dataframe and the trained classifier\n",
    "    return results, classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7905913493352584\n",
      "                          Actual                Predicted\n",
      "772702   Closed with explanation  Closed with explanation\n",
      "641726   Closed with explanation  Closed with explanation\n",
      "799623   Closed with explanation  Closed with explanation\n",
      "1081959  Closed with explanation  Closed with explanation\n",
      "859568   Closed with explanation  Closed with explanation\n",
      "...                          ...                      ...\n",
      "671381                    Closed  Closed with explanation\n",
      "952334                    Closed  Closed with explanation\n",
      "926664                    Closed  Closed with explanation\n",
      "899697                    Closed  Closed with explanation\n",
      "237351                    Closed  Closed with explanation\n",
      "\n",
      "[49869 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hyperparameters = {\n",
    "    'max_depth': 5,\n",
    "    'min_samples_split': 2\n",
    "}\n",
    "\n",
    "results, classifier = run_decision_tree_classifier(X_train_tfe, y_train,X_val_tfe, y_val, **hyperparameters)\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7916942389059336\n",
      "                          Actual                Predicted\n",
      "772702   Closed with explanation  Closed with explanation\n",
      "641726   Closed with explanation  Closed with explanation\n",
      "799623   Closed with explanation  Closed with explanation\n",
      "1081959  Closed with explanation  Closed with explanation\n",
      "859568   Closed with explanation  Closed with explanation\n",
      "...                          ...                      ...\n",
      "671381                    Closed  Closed with explanation\n",
      "952334                    Closed  Closed with explanation\n",
      "926664                    Closed  Closed with explanation\n",
      "899697                    Closed  Closed with explanation\n",
      "237351                    Closed  Closed with explanation\n",
      "\n",
      "[49869 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 4\n",
    "}\n",
    "\n",
    "results, classifier = run_decision_tree_classifier(X_train_tfe, y_train,X_val_tfe, y_val, **hyperparameters)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7905712967976097\n",
      "                          Actual                Predicted\n",
      "772702   Closed with explanation  Closed with explanation\n",
      "641726   Closed with explanation  Closed with explanation\n",
      "799623   Closed with explanation  Closed with explanation\n",
      "1081959  Closed with explanation  Closed with explanation\n",
      "859568   Closed with explanation  Closed with explanation\n",
      "...                          ...                      ...\n",
      "671381                    Closed  Closed with explanation\n",
      "952334                    Closed  Closed with explanation\n",
      "926664                    Closed  Closed with explanation\n",
      "899697                    Closed  Closed with explanation\n",
      "237351                    Closed  Closed with explanation\n",
      "\n",
      "[49869 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'max_depth': 5,\n",
    "    'min_samples_split': 10\n",
    "}\n",
    "\n",
    "results, classifier = run_decision_tree_classifier(X_train_tfe, y_train,X_val_tfe, y_val, **hyperparameters)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7879043092903407\n",
      "                          Actual                Predicted\n",
      "772702   Closed with explanation  Closed with explanation\n",
      "641726   Closed with explanation  Closed with explanation\n",
      "799623   Closed with explanation  Closed with explanation\n",
      "1081959  Closed with explanation  Closed with explanation\n",
      "859568   Closed with explanation  Closed with explanation\n",
      "...                          ...                      ...\n",
      "671381                    Closed  Closed with explanation\n",
      "952334                    Closed  Closed with explanation\n",
      "926664                    Closed  Closed with explanation\n",
      "899697                    Closed  Closed with explanation\n",
      "237351                    Closed  Closed with explanation\n",
      "\n",
      "[49869 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'max_depth': 1,\n",
    "    'min_samples_split': 10\n",
    "}\n",
    "\n",
    "results, classifier = run_decision_tree_classifier(X_train_tfe, y_train,X_val_tfe, y_val, **hyperparameters)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_decision_trees(X_train, y_train, X_val, y_val):\n",
    "    hyperparameters = list(range(1, 11))  # Range of hyperparameters\n",
    "    \n",
    "    results = pd.DataFrame()  # Dataframe to hold the results\n",
    "    models = []  # List to hold the trained classifiers\n",
    "    \n",
    "    for param in hyperparameters:\n",
    "        print(\"Running model with hyperparameter:\", param)\n",
    "        \n",
    "        # Run the decision tree classifier with current hyperparameter\n",
    "        res, clf, train_acc, val_acc = run_decision_tree_classifier(X_train, y_train, X_val, y_val, max_depth=param)\n",
    "        \n",
    "        # Append the results to the dataframe\n",
    "        results = pd.concat([results, res], ignore_index=True)\n",
    "        \n",
    "        # Append the trained classifier to the list\n",
    "        models.append(clf)\n",
    "        \n",
    "    # Sort the models based on validation accuracy\n",
    "    sorted_models = sorted(zip(models, hyperparameters), key=lambda x: x[0].score(X_val, y_val), reverse=True)\n",
    "    \n",
    "    # Print the top 5 models based on validation accuracy\n",
    "    print(\"Top 5 models based on validation accuracy:\")\n",
    "    for i, (model, param) in enumerate(sorted_models[:5], 1):\n",
    "        train_acc = model.score(X_train, y_train)\n",
    "        val_acc = model.score(X_val, y_val)\n",
    "        print(f\"Model {i}: Hyperparameter: {param}, Train Accuracy: {train_acc:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "    \n",
    "    # Return the results dataframe and the list of trained classifiers\n",
    "    return results, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wd/5_z1tvw94pv9x2ld8p_0dl2r0000gn/T/ipykernel_15376/2439757652.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentiment_df\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/codeup-data-science/consumer-complaint-response/wrangle.py\u001b[0m in \u001b[0;36msentiment_analysis\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0msia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;31m# Apply the sentiment intensity analyzer to the 'lemon' column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lemon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mcomplaint\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplaint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compound'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplaint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4431\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4432\u001b[0m         \"\"\"\n\u001b[0;32m-> 4433\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4435\u001b[0m     def _reduce(\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                 \u001b[0;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1144\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/codeup-data-science/consumer-complaint-response/wrangle.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(complaint)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0msia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;31m# Apply the sentiment intensity analyzer to the 'lemon' column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lemon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mcomplaint\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplaint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compound'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplaint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36mpolarity_scores\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0msentiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment_valence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentitext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0msentiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_but_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_and_emoticons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36msentiment_valence\u001b[0;34m(self, valence, sentitext, item, i, sentiments)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mvalence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_least_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_and_emoticons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         \u001b[0msentiments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msentiments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sentiment_df= w.sentiment_analysis(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = sentiment_df.groupby(['product_bins', 'company_response_to_consumer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_bins     company_response_to_consumer   \n",
       "bank             Closed                            -0.128198\n",
       "                 Closed with explanation           -0.066920\n",
       "                 Closed with monetary relief       -0.059679\n",
       "                 Closed with non-monetary relief    0.070788\n",
       "                 Untimely response                 -0.170290\n",
       "credit_card      Closed                             0.175603\n",
       "                 Closed with explanation            0.225597\n",
       "                 Closed with monetary relief        0.166649\n",
       "                 Closed with non-monetary relief    0.282641\n",
       "                 Untimely response                  0.146639\n",
       "credit_report    Closed                             0.189479\n",
       "                 Closed with explanation            0.128327\n",
       "                 Closed with monetary relief        0.311037\n",
       "                 Closed with non-monetary relief    0.088647\n",
       "                 Untimely response                  0.178200\n",
       "debt_collection  Closed                            -0.196091\n",
       "                 Closed with explanation           -0.153791\n",
       "                 Closed with monetary relief       -0.022336\n",
       "                 Closed with non-monetary relief   -0.156969\n",
       "                 Untimely response                 -0.294647\n",
       "loans            Closed                             0.058413\n",
       "                 Closed with explanation            0.166600\n",
       "                 Closed with monetary relief        0.187695\n",
       "                 Closed with non-monetary relief    0.168204\n",
       "                 Untimely response                  0.101218\n",
       "money_service    Closed                            -0.334820\n",
       "                 Closed with explanation            0.014134\n",
       "                 Closed with monetary relief       -0.053576\n",
       "                 Closed with non-monetary relief    0.030993\n",
       "                 Untimely response                  0.108920\n",
       "mortgage         Closed                             0.079552\n",
       "                 Closed with explanation            0.136486\n",
       "                 Closed with monetary relief        0.197979\n",
       "                 Closed with non-monetary relief    0.194208\n",
       "                 Untimely response                  0.219436\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = grouped_df['sentiment'].mean()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Closed with explanation            589373\n",
       "Closed with non-monetary relief    123170\n",
       "Closed with monetary relief         30578\n",
       "Untimely response                    2675\n",
       "Closed                               2245\n",
       "Name: company_response_to_consumer, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.company_response_to_consumer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_received</th>\n",
       "      <th>company_name</th>\n",
       "      <th>state</th>\n",
       "      <th>tags</th>\n",
       "      <th>company_response_to_consumer</th>\n",
       "      <th>product_bins</th>\n",
       "      <th>clean</th>\n",
       "      <th>lemon</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>944870</th>\n",
       "      <td>2015-05-12</td>\n",
       "      <td>CITIBANK, N.A.</td>\n",
       "      <td>CA</td>\n",
       "      <td>Average Person</td>\n",
       "      <td>Closed with monetary relief</td>\n",
       "      <td>mortgage</td>\n",
       "      <td>it has been since that i first applied for the...</td>\n",
       "      <td>since first applied refinance today decision c...</td>\n",
       "      <td>-0.9899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570225</th>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>EQUIFAX, INC.</td>\n",
       "      <td>CA</td>\n",
       "      <td>Average Person</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>credit_report</td>\n",
       "      <td>inquiry ive called and informed them that i di...</td>\n",
       "      <td>inquiry ive called informed applied car inquir...</td>\n",
       "      <td>0.3818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523256</th>\n",
       "      <td>2017-10-11</td>\n",
       "      <td>Franklin Collection Service, Inc.</td>\n",
       "      <td>GA</td>\n",
       "      <td>Average Person</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>debt_collection</td>\n",
       "      <td>i paid the bill in hopes to get it back but th...</td>\n",
       "      <td>paid bill hope get back said pay different ins...</td>\n",
       "      <td>0.1779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753529</th>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>Credit Plus Inc</td>\n",
       "      <td>CA</td>\n",
       "      <td>Average Person</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>credit_report</td>\n",
       "      <td>unknown inquiry on my credit reports from cred...</td>\n",
       "      <td>unknown inquiry credit report credit plus auth...</td>\n",
       "      <td>0.8555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999772</th>\n",
       "      <td>2016-06-17</td>\n",
       "      <td>Selene Finance LP</td>\n",
       "      <td>OR</td>\n",
       "      <td>Average Person</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>mortgage</td>\n",
       "      <td>selene finance will not help me figure out why...</td>\n",
       "      <td>selene finance help figure many different amou...</td>\n",
       "      <td>-0.1531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_received                       company_name state            tags  \\\n",
       "944870    2015-05-12                     CITIBANK, N.A.    CA  Average Person   \n",
       "570225    2021-07-06                      EQUIFAX, INC.    CA  Average Person   \n",
       "523256    2017-10-11  Franklin Collection Service, Inc.    GA  Average Person   \n",
       "753529    2017-12-18                    Credit Plus Inc    CA  Average Person   \n",
       "999772    2016-06-17                  Selene Finance LP    OR  Average Person   \n",
       "\n",
       "       company_response_to_consumer     product_bins  \\\n",
       "944870  Closed with monetary relief         mortgage   \n",
       "570225      Closed with explanation    credit_report   \n",
       "523256      Closed with explanation  debt_collection   \n",
       "753529      Closed with explanation    credit_report   \n",
       "999772      Closed with explanation         mortgage   \n",
       "\n",
       "                                                    clean  \\\n",
       "944870  it has been since that i first applied for the...   \n",
       "570225  inquiry ive called and informed them that i di...   \n",
       "523256  i paid the bill in hopes to get it back but th...   \n",
       "753529  unknown inquiry on my credit reports from cred...   \n",
       "999772  selene finance will not help me figure out why...   \n",
       "\n",
       "                                                    lemon  sentiment  \n",
       "944870  since first applied refinance today decision c...    -0.9899  \n",
       "570225  inquiry ive called informed applied car inquir...     0.3818  \n",
       "523256  paid bill hope get back said pay different ins...     0.1779  \n",
       "753529  unknown inquiry credit report credit plus auth...     0.8555  \n",
       "999772  selene finance help figure many different amou...    -0.1531  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "\n",
    "def run_decision_tree_classifier(X_train, y_train, X_val, y_val, **kwargs):\n",
    "    # Initialize the decision tree classifier with hyperparameters\n",
    "    classifier = DecisionTreeClassifier(**kwargs)\n",
    "    \n",
    "    # Train the classifier\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_pred = classifier.predict(X_val)\n",
    "    \n",
    "    # Calculate the accuracy and recall scores of the classifier\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    recall_train = recall_score(y_train, classifier.predict(X_train), average='micro')\n",
    "    recall_val = recall_score(y_val, y_pred, average='micro')\n",
    "    \n",
    "    # Create a dataframe to hold the results\n",
    "    results = pd.DataFrame({\n",
    "        'Actual': y_val,\n",
    "        'Predicted': y_pred\n",
    "    })\n",
    "    \n",
    "    # Print the accuracy and recall scores\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Recall (Train):\", recall_train)\n",
    "    print(\"Recall (Validation):\", recall_val)\n",
    "    \n",
    "    # Return the results dataframe and the trained classifier\n",
    "    return results, classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7913533457659067\n",
      "Recall (Train): 0.23937176636949098\n",
      "Recall (Validation): 0.22815735005161036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                          Actual                Predicted\n",
       " 772702   Closed with explanation  Closed with explanation\n",
       " 641726   Closed with explanation  Closed with explanation\n",
       " 799623   Closed with explanation  Closed with explanation\n",
       " 1081959  Closed with explanation  Closed with explanation\n",
       " 859568   Closed with explanation  Closed with explanation\n",
       " ...                          ...                      ...\n",
       " 671381                    Closed  Closed with explanation\n",
       " 952334                    Closed  Closed with explanation\n",
       " 926664                    Closed  Closed with explanation\n",
       " 899697                    Closed  Closed with explanation\n",
       " 237351                    Closed  Closed with explanation\n",
       " \n",
       " [49869 rows x 2 columns],\n",
       " DecisionTreeClassifier(max_depth=8, min_samples_split=12))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'max_depth': 8,\n",
    "    'min_samples_split': 12\n",
    "}\n",
    "\n",
    "\n",
    "run_decision_tree_classifier(X_train_tfe, y_train,X_val_tfe, y_val, **hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7913733983035554\n",
      "Recall (Train): 0.7987955270070651\n",
      "Recall (Validation): 0.7913733983035554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                          Actual                Predicted\n",
       " 772702   Closed with explanation  Closed with explanation\n",
       " 641726   Closed with explanation  Closed with explanation\n",
       " 799623   Closed with explanation  Closed with explanation\n",
       " 1081959  Closed with explanation  Closed with explanation\n",
       " 859568   Closed with explanation  Closed with explanation\n",
       " ...                          ...                      ...\n",
       " 671381                    Closed  Closed with explanation\n",
       " 952334                    Closed  Closed with explanation\n",
       " 926664                    Closed  Closed with explanation\n",
       " 899697                    Closed  Closed with explanation\n",
       " 237351                    Closed  Closed with explanation\n",
       " \n",
       " [49869 rows x 2 columns],\n",
       " DecisionTreeClassifier(max_depth=8, min_samples_split=12))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'max_depth': 8,\n",
    "    'min_samples_split': 12\n",
    "}\n",
    "\n",
    "\n",
    "run_decision_tree_classifier(X_train_tfe, y_train,X_val_tfe, y_val, **hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7917945015941767\n",
      "Recall (Train): 0.8053058305315857\n",
      "Recall (Validation): 0.7917945015941767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                          Actual                Predicted\n",
       " 772702   Closed with explanation  Closed with explanation\n",
       " 641726   Closed with explanation  Closed with explanation\n",
       " 799623   Closed with explanation  Closed with explanation\n",
       " 1081959  Closed with explanation  Closed with explanation\n",
       " 859568   Closed with explanation  Closed with explanation\n",
       " ...                          ...                      ...\n",
       " 671381                    Closed  Closed with explanation\n",
       " 952334                    Closed  Closed with explanation\n",
       " 926664                    Closed  Closed with explanation\n",
       " 899697                    Closed  Closed with explanation\n",
       " 237351                    Closed  Closed with explanation\n",
       " \n",
       " [49869 rows x 2 columns],\n",
       " DecisionTreeClassifier(max_depth=10, min_samples_split=20))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 20\n",
    "}\n",
    "\n",
    "\n",
    "run_decision_tree_classifier(X_train_tfe, y_train,X_val_tfe, y_val, **hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7913533457659067\n",
      "Recall (Train): 0.7959681569959026\n",
      "Recall (Validation): 0.7913533457659067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                          Actual                Predicted\n",
       " 772702   Closed with explanation  Closed with explanation\n",
       " 641726   Closed with explanation  Closed with explanation\n",
       " 799623   Closed with explanation  Closed with explanation\n",
       " 1081959  Closed with explanation  Closed with explanation\n",
       " 859568   Closed with explanation  Closed with explanation\n",
       " ...                          ...                      ...\n",
       " 671381                    Closed  Closed with explanation\n",
       " 952334                    Closed  Closed with explanation\n",
       " 926664                    Closed  Closed with explanation\n",
       " 899697                    Closed  Closed with explanation\n",
       " 237351                    Closed  Closed with explanation\n",
       " \n",
       " [49869 rows x 2 columns],\n",
       " DecisionTreeClassifier(max_depth=7, min_samples_split=15))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'max_depth': 7,\n",
    "    'min_samples_split': 15\n",
    "}\n",
    "\n",
    "\n",
    "run_decision_tree_classifier(X_train_tfe, y_train,X_val_tfe, y_val, **hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
