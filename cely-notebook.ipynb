{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd41e4d0-a410-497c-832c-d6b8560d1c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrangle as w\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782060bf-505e-4f8e-8e21-3d064d82934c",
   "metadata": {},
   "source": [
    "## Acquire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d7d4cd-c895-432a-b8c0-82df7dccfdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=w.check_file_exists_gbq('cfpb.csv','service_key.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6760923c-befc-44b0-925c-b239c83f672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca25d4-2b1a-4170-84b5-89ca9f3a6f21",
   "metadata": {},
   "source": [
    "## Pre cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0166f9-20ae-4d2c-9972-9ef2aa5e7901",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tags.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e077725-bfe3-447f-bee6-dcfebf6dfe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tags=df.tags.fillna('Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5255cb-4ead-4143-9853-0e346d592d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tags.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62220ad-968c-42f6-abe0-51b19566de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.submitted_via.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1bcc2-fb72-4ac4-a6eb-f94486a72fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.consumer_disputed.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a584ee22-f64d-4e8c-8f02-54f458d5252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b1070d-88bd-4847-aef6-db17a2db4105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.consumer_complaint_narrative.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeca6cdf-7353-4073-96e3-0d288013be08",
   "metadata": {},
   "source": [
    "## Clean Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafc2052-26de-4937-a9cf-d59ee4a28d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=w.clean_data(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26704510-22c3-4a13-ba14-50e73014460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.\tcompany_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374b793b-7357-4ec9-9b64-e901a0a63ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "boa_df=df[df.company_name=='BANK OF AMERICA, NATIONAL ASSOCIATION']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbbc6c1-863c-458f-8fac-3061a7c7e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "boa_df.date_received.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d4dcc3-c00b-49b5-9865-38d6b7c972c9",
   "metadata": {},
   "source": [
    " ## NLTK Language Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746fb7b0-0feb-4c59-ac4c-3ad32f2ab643",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=w.prep_narrative(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd44c7a-4c13-47e4-82ba-c383df985864",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1985760c-585b-4b37-82b4-a94e7cb923a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,validate,test=w.split_data(df,'company_response_to_consumer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80019a-9755-43dd-8805-57992ba6a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet('train.parquet')\n",
    "validate.to_parquet('validate.parquet')\n",
    "test.to_parquet('test.parquet')\n",
    "train = pd.read_parquet('train.parquet')\n",
    "validate = pd.read_parquet('validate.parquet')\n",
    "test = pd.read_parquet('test.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be6c058",
   "metadata": {},
   "source": [
    "# Exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2072ad29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports loaded successfully, awaiting commands...\n"
     ]
    }
   ],
   "source": [
    "import wrangle as w\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as stats\n",
    "import nltk\n",
    "alpha=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07804cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet('train.parquet')\n",
    "validate = pd.read_parquet('validate.parquet')\n",
    "test = pd.read_parquet('test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1845e0f-0a60-49f1-b5ec-40e3aca2e73d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wd/5_z1tvw94pv9x2ld8p_0dl2r0000gn/T/ipykernel_2007/1770750880.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentiment_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/codeup-data-science/consumer-complaint-response/wrangle.py\u001b[0m in \u001b[0;36msentiment_analysis\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;31m# Apply the sentiment intensity analyzer to the 'lemon' column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lemon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mcomplaint\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplaint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compound'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplaint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4431\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4432\u001b[0m         \"\"\"\n\u001b[0;32m-> 4433\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4435\u001b[0m     def _reduce(\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                 \u001b[0;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1144\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/codeup-data-science/consumer-complaint-response/wrangle.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(complaint)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;31m# Apply the sentiment intensity analyzer to the 'lemon' column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lemon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mcomplaint\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplaint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compound'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplaint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36mpolarity_scores\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \"\"\"\n\u001b[1;32m    360\u001b[0m         \u001b[0;31m# text, words_and_emoticons, is_cap_diff = self.preprocess(text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         sentitext = SentiText(\n\u001b[0m\u001b[1;32m    362\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNC_LIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREGEX_REMOVE_PUNCTUATION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, text, punc_list, regex_remove_punctuation)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNC_LIST\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpunc_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREGEX_REMOVE_PUNCTUATION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregex_remove_punctuation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords_and_emoticons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_words_and_emoticons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;31m# doesn't separate words from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;31m# adjacent punctuation (keeps emoticons & contractions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36m_words_and_emoticons\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \"\"\"\n\u001b[1;32m    305\u001b[0m         \u001b[0mwes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mwords_punc_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_words_plus_punc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0mwes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwe\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36m_words_plus_punc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mwords_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords_only\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;31m# the product gives ('cat', ',') and (',', 'cat')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mpunc_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNC_LIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mpunc_after\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNC_LIST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mwords_punc_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpunc_before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mwords_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords_only\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;31m# the product gives ('cat', ',') and (',', 'cat')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mpunc_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNC_LIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mpunc_after\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNC_LIST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mwords_punc_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpunc_before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sentiment_df=w.sentiment_analysis(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25199022-7592-4bef-bee7-cb4af891d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52ced02",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccce996-4f35-4016-a9a4-cd148eba8f97",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Do narratives with a neutral or positive sentiment analysis relating to bank account products lead to a response of closed with monetary relief?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056bda32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.company_response_to_consumer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d022e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.product_bins.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76ddf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwe_df=sentiment_df[sentiment_df.company_response_to_consumer=='Closed with explanation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c5b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.boxplot(data=sentiment_df, x='product_bins', y='sentiment', hue='company_response_to_consumer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8c3a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=sentiment_df, x='product_bins', y='sentiment', hue='company_response_to_consumer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c99fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.kdeplot(sentiment_df[sentiment_df.company_response_to_consumer=='Closed with monetary relief'].sentiment, label='money')\n",
    "sns.kdeplot(sentiment_df[sentiment_df.company_response_to_consumer=='Closed with non-monetary relief'].sentiment, label='no money')\n",
    "sns.kdeplot(sentiment_df[sentiment_df.company_response_to_consumer=='Closed with explanation'].sentiment, label='explanation')\n",
    "sns.kdeplot(sentiment_df[sentiment_df.company_response_to_consumer=='Untimely response'].sentiment, label='late response')\n",
    "sns.kdeplot(sentiment_df[sentiment_df.company_response_to_consumer=='Closed'].sentiment, label='no explanation')\n",
    "plt.legend(['money', 'no money','explanation','late response','no explanation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451280c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181e26e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Customize the plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create the bar plot\n",
    "sns.barplot(data=sentiment_df, x='product_bins', y='sentiment', hue='company_response_to_consumer', ci=None, color='purple')\n",
    "\n",
    "# Set the labels and title\n",
    "plt.xlabel('Product Bins')\n",
    "plt.ylabel('Sentiment')\n",
    "plt.title('Company Response to Consumer and Sentiment across Product Bins')\n",
    "\n",
    "# Adjust the legend position\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55358f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create example data\n",
    "group1 = np.random.normal(loc=10, scale=2, size=100)\n",
    "group2 = np.random.normal(loc=12, scale=2, size=100)\n",
    "\n",
    "# Calculate the theoretical means for each group\n",
    "theoretical_mean_group1 = np.mean(group1)\n",
    "theoretical_mean_group2 = np.mean(group2)\n",
    "\n",
    "# Combine the group data and assign a group label\n",
    "data = pd.DataFrame({'group1': group1,\n",
    "                     'group2': group2})\n",
    "\n",
    "# Set the significance level (alpha)\n",
    "alpha = 0.05\n",
    "\n",
    "# Perform Levene test for variance comparison\n",
    "tstat, pvalue = stats.levene(group1, group2)\n",
    "\n",
    "print(\"Running Levene Test...\")\n",
    "if pvalue > alpha:\n",
    "    print(f'p-value: {pvalue:.10f} > {alpha}?')\n",
    "    print(\"Variance is true, proceed with ANOVA test...\")\n",
    "else:\n",
    "    print(\"p-value:\", pvalue)\n",
    "    print(\"Variance is not true. Consider alternative tests for comparing groups.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cecca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get unique categories of product_bins\n",
    "unique_bins = sentiment_df['product_bins'].unique()\n",
    "\n",
    "# Perform ANOVA test for each category of product_bins\n",
    "for bin_category in unique_bins:\n",
    "    # Create a subset of the data for the specific product_bins category\n",
    "    subset = sentiment_df[sentiment_df['product_bins'] == bin_category]\n",
    "\n",
    "    # Perform one-way ANOVA for the subset\n",
    "    result = stats.f_oneway(*[subset[subset['company_response_to_consumer'] == response]['sentiment']\n",
    "                              for response in subset['company_response_to_consumer'].unique()])\n",
    "\n",
    "    # Print the ANOVA test result for the subset\n",
    "    print(\"Product Bins:\", bin_category)\n",
    "    print(\"ANOVA p-value:\", result.pvalue)\n",
    "\n",
    "    if result.pvalue < alpha:\n",
    "        print(\"The p-value is less than alpha. There is a significant effect of sentiment on company response to the consumer.\")\n",
    "    else:\n",
    "        print(\"The p-value is greater than or equal to alpha. There is no significant effect of sentiment on company response to the consumer.\")\n",
    "\n",
    "    print()  # Print an empty line between each category's results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532295a0-61a7-4b11-934f-44f5f1eebb72",
   "metadata": {},
   "source": [
    "## 6.Does narrative length relate to company response?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f394c540-c414-4d27-ba4d-e7a777eefc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df['message_length'] = sentiment_df['clean'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c3aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df['word_count'] = sentiment_df['lemon'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55670603",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df['word_count'] = sentiment_df['lemon'].apply(lambda x: len(x.split()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856e0c0b",
   "metadata": {},
   "source": [
    "sentiment_df['word_count'] = sentiment_df.narrative.apply(w.basic_clean).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8779d5a0-4629-4b5d-97e9-ea376543c285",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f75aa-979f-4059-a554-1e34b5bc6d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=sentiment_df, x='message_length', y='sentiment', hue='company_response_to_consumer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552180d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=sentiment_df, x='word_count', y='sentiment', hue='company_response_to_consumer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca96105",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cm.list_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5877da-87b3-4a51-ac6a-8c481f19ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sentiment_df['message_length'], sentiment_df['company_response_to_consumer'],cmap='Set1')\n",
    "\n",
    "plt.xlabel('Message Length')\n",
    "plt.ylabel('Company Response to Consumer')\n",
    "plt.title('Relationship between Message Length and Company Response to Consumer')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a414f747",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sentiment_df['word_count'], sentiment_df['company_response_to_consumer'],cmap='red')\n",
    "\n",
    "plt.xlabel('Word Count')\n",
    "plt.ylabel('Company Response to Consumer')\n",
    "plt.title('Relationship between Word Count and Company Response to Consumer')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5829abd-5ca0-4d9c-9dce-9845ea2b3f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = stats.f_oneway(*[sentiment_df[sentiment_df['company_response_to_consumer'] == response]['message_length']\n",
    "                          for response in sentiment_df['company_response_to_consumer'].unique()])\n",
    "\n",
    "p_value = result.pvalue\n",
    "\n",
    "\n",
    "print(\"ANOVA p-value:\", p_value)\n",
    "if p_value < alpha:\n",
    "    print(\"The p-value is less than alpha. There is a significant relationship between message length and company response to the consumer.\")\n",
    "else:\n",
    "    print(\"The p-value is greater than or equal to alpha. There is no significant relationship between message length and company response to the consumer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7855d46b",
   "metadata": {},
   "source": [
    "## Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ab663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(sentiment_df, alpha=0.05,truncate=False):\n",
    "    \"\"\"Analyzes sentiment and company response to consumer across product bins.\n",
    "    This function answers the question: Do narratives with a neutral or positive sentiment\n",
    "    analysis relating to bank account products lead to a response of closed with monetary relief?\"\"\"\n",
    "\n",
    "    # Set the figure size\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Customize the plot style\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # Create the bar plot\n",
    "    sns.barplot(data=sentiment_df, x='product_bins', y='sentiment', hue='company_response_to_consumer', ci=None, color='purple')\n",
    "\n",
    "    # Set the labels and title\n",
    "    plt.xlabel('Product Bins')\n",
    "    plt.ylabel('Sentiment')\n",
    "    plt.title('Company Response to Consumer and Sentiment Analysis across Product Bins')\n",
    "\n",
    "    # Adjust the legend position\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "   # Create example data for Levene test\n",
    "    group1 = np.random.normal(loc=10, scale=2, size=100)\n",
    "    group2 = np.random.normal(loc=12, scale=2, size=100)\n",
    "\n",
    "    # Calculate the theoretical means for each group\n",
    "    theoretical_mean_group1 = np.mean(group1)\n",
    "    theoretical_mean_group2 = np.mean(group2)\n",
    "\n",
    "    # Perform Levene test for variance comparison\n",
    "    tstat, pvalue = stats.levene(group1, group2)\n",
    "\n",
    "    print(\"Running Levene Test...\")\n",
    "    if pvalue > alpha:\n",
    "        print(f'p-value: {pvalue:.10f} > {alpha}?')\n",
    "        print()\n",
    "        print(\"Variance is true, proceed with ANOVA test...\")\n",
    "        print()\n",
    "    else:\n",
    "        print(\"p-value:\", pvalue)\n",
    "        print()\n",
    "        print(\"Variance is not true. Consider alternative tests for comparing groups.\")\n",
    "        print()\n",
    "\n",
    "    # Get unique categories of product_bins\n",
    "    unique_bins = sentiment_df['product_bins'].unique()\n",
    "\n",
    "    # Perform ANOVA test for each category of product_bins\n",
    "    for bin_category in unique_bins:\n",
    "        # Create a subset of the data for the specific product_bins category\n",
    "        subset = sentiment_df[sentiment_df['product_bins'] == bin_category]\n",
    "\n",
    "        # Perform one-way ANOVA for the subset\n",
    "        result = stats.f_oneway(*[subset[subset['company_response_to_consumer'] == response]['sentiment']\n",
    "                                  for response in subset['company_response_to_consumer'].unique()])\n",
    "\n",
    "        # Print the ANOVA test result for the subset\n",
    "        print(\"Product Bins:\", bin_category)\n",
    "        print(\"ANOVA p-value:\", result.pvalue)\n",
    "\n",
    "        if result.pvalue < alpha:\n",
    "            print(\"The p-value is less than alpha. There is a significant effect of sentiment on company response to the consumer.\")\n",
    "        else:\n",
    "            print(\"The p-value is greater than or equal to alpha. There is no significant effect of sentiment on company response to the consumer.\")\n",
    "\n",
    "        print()  # Print an empty line between each category's results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb787243",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_sentiment(sentiment_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a90711d",
   "metadata": {},
   "source": [
    "### Takeaways:\n",
    "- Overall, there is a strong correlation between the sentiment of consumer complaints/narratives and the corresponding responses from companies.\n",
    "\n",
    "1. Mortgage:\n",
    "  - Consumer complaints/narratives exhibit predominantly positive sentiment, and companies provide an equal distribution of responses across different categories.\n",
    "  \n",
    "2. Credit Report:\n",
    "  - Consumer complaints/narratives with positive sentiment tend to receive the \"closed with monetary relief\" response most frequently.\n",
    "  - Overall, the sentiment of complaints/narratives is generally neutral to positive.\n",
    "  \n",
    "3. Debt Collection:\n",
    "  - All consumer complaints/narratives have negative sentiment scores, and the complaints with the most negative scores typically receive an \"untimely response.\"\n",
    "  \n",
    "4. Loans:\n",
    "  - Complaints/narratives regarding loans have sentiment scores ranging from neutral to positive. Companies provide different responses irrespective of the sentiment score.\n",
    "   \n",
    "5. Bank:\n",
    "  - Sentiment scores for bank-related complaints/narratives are somewhat mixed, ranging from neutral to negative. The more negative complaints tend to receive a \"closed\" or \"untimely response.\"\n",
    "  \n",
    "6. Money Service:\n",
    "  - Sentiment scores for complaints/narratives about money services vary between negative and positive. The most negative complaints receive a \"closed\" response.\n",
    "  \n",
    "7. Credit Card:\n",
    " - The majority of sentiment scores for credit card complaints/narratives range from neutral to positive. The most common response received by consumers is \"closed with non-monetary relief.\"\n",
    " \n",
    " - These findings indicate that the sentiment of consumer complaints/narratives has an influence on the type of response received from companies across different industry sectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0f3af1",
   "metadata": {},
   "source": [
    "## Summary \n",
    "* The analysis revealed a significant relationship between consumer sentiment in complaints/narratives and the corresponding company responses, indicating the importance of sentiment in consumer-company interactions.\n",
    "* Sentiment patterns varied across industries, with positive sentiment in mortgage complaints, credit report complaints receiving \"closed with monetary relief\" responses, and consistently negative sentiment in debt collection complaints leading to \"untimely response\" from companies. These findings highlight the need to consider sentiment for effective consumer grievance resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3049b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_message_length(sentiment_df, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Analyzes the relationship between message length and company response to the consumer.\n",
    "    This function answers the question: Does narrative length relate to company response?\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the scatter plot\n",
    "    plt.scatter(sentiment_df['message_length'], sentiment_df['company_response_to_consumer'], cmap='Set1')\n",
    "\n",
    "    # Set the labels and title\n",
    "    plt.xlabel('Message Length')\n",
    "    plt.ylabel('Company Response to Consumer')\n",
    "    plt.title('Relationship between Message Length and Company Response to Consumer')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Perform ANOVA test\n",
    "    # The code then uses a list comprehension to iterate over each unique category.\n",
    "    result = stats.f_oneway(*[sentiment_df[sentiment_df['company_response_to_consumer'] == response]['message_length']\n",
    "                              for response in sentiment_df['company_response_to_consumer'].unique()])\n",
    "\n",
    "    p_value = result.pvalue\n",
    "\n",
    "    print(\"ANOVA p-value:\", p_value)\n",
    "    if p_value < alpha:\n",
    "        print(\"The p-value is less than alpha. There is a significant relationship between message length and company response to the consumer.\")\n",
    "    else:\n",
    "        print(\"The p-value is greater than or equal to alpha. There is no significant relationship between message length and company response to the consumer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd7071",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_message_length(sentiment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f4c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_word_count(sentiment_df, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Analyzes the relationship between word count and company response to the consumer.\n",
    "    This function answers the question: Does narrative word count relate to company response?\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the scatter plot\n",
    "    plt.scatter(sentiment_df['message_length'], sentiment_df['company_response_to_consumer'], cmap='Set1')\n",
    "\n",
    "    # Set the labels and title\n",
    "    plt.xlabel('Message Length')\n",
    "    plt.ylabel('Company Response to Consumer')\n",
    "    plt.title('Relationship between Message Length and Company Response to Consumer')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Perform ANOVA test\n",
    "    # The code then uses a list comprehension to iterate over each unique category.\n",
    "    result = stats.f_oneway(*[sentiment_df[sentiment_df['company_response_to_consumer'] == response]['message_length']\n",
    "                              for response in sentiment_df['company_response_to_consumer'].unique()])\n",
    "\n",
    "    p_value = result.pvalue\n",
    "\n",
    "    print(\"ANOVA p-value:\", p_value)\n",
    "    if p_value < alpha:\n",
    "        print(\"The p-value is less than alpha. There is a significant relationship between message length and company response to the consumer.\")\n",
    "    else:\n",
    "        print(\"The p-value is greater than or equal to alpha. There is no significant relationship between message length and company response to the consumer.\")\n",
    "    # Create the scatter plot\n",
    "    plt.scatter(sentiment_df['word_count'], sentiment_df['company_response_to_consumer'], cmap='Reds')\n",
    "\n",
    "    # Set the labels and title\n",
    "    plt.xlabel('Word Count')\n",
    "    plt.ylabel('Company Response to Consumer')\n",
    "    plt.title('Relationship between Word Count and Company Response to Consumer')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Perform ANOVA test\n",
    "    # The code uses a list comprehension to iterate over each unique category.\n",
    "    result = stats.f_oneway(*[sentiment_df[sentiment_df['company_response_to_consumer'] == response]['word_count']\n",
    "                              for response in sentiment_df['company_response_to_consumer'].unique()])\n",
    "\n",
    "    p_value = result.pvalue\n",
    "\n",
    "    print(\"ANOVA p-value:\", p_value)\n",
    "    if p_value < alpha:\n",
    "        print(\"The p-value is less than alpha. There is a significant relationship between word count and company response to the consumer.\")\n",
    "    else:\n",
    "        print(\"The p-value is greater than or equal to alpha. There is no significant relationship between word count and company response to the consumer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a9985",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_word_count(sentiment_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3fc4f8",
   "metadata": {},
   "source": [
    "## Modeling attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd280cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00b25431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_received</th>\n",
       "      <th>company_name</th>\n",
       "      <th>state</th>\n",
       "      <th>tags</th>\n",
       "      <th>company_response_to_consumer</th>\n",
       "      <th>product_bins</th>\n",
       "      <th>clean</th>\n",
       "      <th>lemon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>944870</th>\n",
       "      <td>2015-05-12</td>\n",
       "      <td>CITIBANK, N.A.</td>\n",
       "      <td>CA</td>\n",
       "      <td>Average Person</td>\n",
       "      <td>Closed with monetary relief</td>\n",
       "      <td>mortgage</td>\n",
       "      <td>it has been since that i first applied for the...</td>\n",
       "      <td>since first applied refinance today decision c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570225</th>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>EQUIFAX, INC.</td>\n",
       "      <td>CA</td>\n",
       "      <td>Average Person</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>credit_report</td>\n",
       "      <td>inquiry ive called and informed them that i di...</td>\n",
       "      <td>inquiry ive called informed applied car inquir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523256</th>\n",
       "      <td>2017-10-11</td>\n",
       "      <td>Franklin Collection Service, Inc.</td>\n",
       "      <td>GA</td>\n",
       "      <td>Average Person</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>debt_collection</td>\n",
       "      <td>i paid the bill in hopes to get it back but th...</td>\n",
       "      <td>paid bill hope get back said pay different ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753529</th>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>Credit Plus Inc</td>\n",
       "      <td>CA</td>\n",
       "      <td>Average Person</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>credit_report</td>\n",
       "      <td>unknown inquiry on my credit reports from cred...</td>\n",
       "      <td>unknown inquiry credit report credit plus auth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999772</th>\n",
       "      <td>2016-06-17</td>\n",
       "      <td>Selene Finance LP</td>\n",
       "      <td>OR</td>\n",
       "      <td>Average Person</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>mortgage</td>\n",
       "      <td>selene finance will not help me figure out why...</td>\n",
       "      <td>selene finance help figure many different amou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_received                       company_name state            tags  \\\n",
       "944870    2015-05-12                     CITIBANK, N.A.    CA  Average Person   \n",
       "570225    2021-07-06                      EQUIFAX, INC.    CA  Average Person   \n",
       "523256    2017-10-11  Franklin Collection Service, Inc.    GA  Average Person   \n",
       "753529    2017-12-18                    Credit Plus Inc    CA  Average Person   \n",
       "999772    2016-06-17                  Selene Finance LP    OR  Average Person   \n",
       "\n",
       "       company_response_to_consumer     product_bins  \\\n",
       "944870  Closed with monetary relief         mortgage   \n",
       "570225      Closed with explanation    credit_report   \n",
       "523256      Closed with explanation  debt_collection   \n",
       "753529      Closed with explanation    credit_report   \n",
       "999772      Closed with explanation         mortgage   \n",
       "\n",
       "                                                    clean  \\\n",
       "944870  it has been since that i first applied for the...   \n",
       "570225  inquiry ive called and informed them that i di...   \n",
       "523256  i paid the bill in hopes to get it back but th...   \n",
       "753529  unknown inquiry on my credit reports from cred...   \n",
       "999772  selene finance will not help me figure out why...   \n",
       "\n",
       "                                                    lemon  \n",
       "944870  since first applied refinance today decision c...  \n",
       "570225  inquiry ive called informed applied car inquir...  \n",
       "523256  paid bill hope get back said pay different ins...  \n",
       "753529  unknown inquiry credit report credit plus auth...  \n",
       "999772  selene finance help figure many different amou...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6675c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = m.encode(train)\n",
    "X_train = X_train.drop(columns=['date_received','company_response_to_consumer','clean','state','company_name','tags','product_bins'])\n",
    "y_train = train['company_response_to_consumer']\n",
    "X_val = m.encode(validate)\n",
    "X_val = X_val.drop(columns=['date_received','company_response_to_consumer','clean','state','company_name','tags','product_bins'])\n",
    "y_val = validate['company_response_to_consumer']\n",
    "X_test = m.encode(test)\n",
    "X_test = X_test.drop(columns=['date_received','company_response_to_consumer','clean','state','company_name','tags','product_bins'])\n",
    "y_test = test['company_response_to_consumer']\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63435192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9df133ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>944870</th>\n",
       "      <td>since first applied refinance today decision c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570225</th>\n",
       "      <td>inquiry ive called informed applied car inquir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523256</th>\n",
       "      <td>paid bill hope get back said pay different ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753529</th>\n",
       "      <td>unknown inquiry credit report credit plus auth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999772</th>\n",
       "      <td>selene finance help figure many different amou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    lemon\n",
       "944870  since first applied refinance today decision c...\n",
       "570225  inquiry ive called informed applied car inquir...\n",
       "523256  paid bill hope get back said pay different ins...\n",
       "753529  unknown inquiry credit report credit plus auth...\n",
       "999772  selene finance help figure many different amou..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train[['lemon']]\n",
    "y_train = train['company_response_to_consumer']\n",
    "X_val = validate[['lemon']]\n",
    "y_val = validate['company_response_to_consumer']\n",
    "X_test = test[['lemon']]\n",
    "y_test = test['company_response_to_consumer']\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d17159c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv,X_val_cv,X_test_cv = m.make_cv(X_train, X_val, X_test)\n",
    "X_train_tf,X_val_tf,X_test_tf = m.make_tfidf(X_train, X_val, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32bbbf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_models(Xtr,ytr,Xv,yv):\n",
    "    metrics = []\n",
    "# cycle through depth, leaf, class_weight for dec tree\n",
    "    for d, l, cw in itertools.product(range(1, 6), range(1, 6), ['balanced', None]):\n",
    "        # decision tree\n",
    "        tree = DecisionTreeClassifier(max_depth=d, min_samples_leaf=l, class_weight=cw, random_state=123)\n",
    "        tree.fit(Xtr, ytr)\n",
    "        # accuracies\n",
    "        ytr_acc = tree.score(Xtr, ytr)\n",
    "        yv_acc = tree.score(Xv, yv)\n",
    "        # table-ize\n",
    "        output = {\n",
    "            'model': 'Decision Tree',\n",
    "            'params': f\"max_depth={d}, min_samples_leaf={l}, class_weight={cw}, random_state=123\",\n",
    "            'tr_acc': ytr_acc,\n",
    "            'v_acc': yv_acc,\n",
    "        }\n",
    "        metrics.append(output)\n",
    "    return pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f752104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_models(X_train_cv,y_train,X_val_cv,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "105ff15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemon</th>\n",
       "      <th>Older American</th>\n",
       "      <th>Older American, Servicemember</th>\n",
       "      <th>Servicemember</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>credit_report</th>\n",
       "      <th>debt_collection</th>\n",
       "      <th>loans</th>\n",
       "      <th>money_service</th>\n",
       "      <th>mortgage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48045</th>\n",
       "      <td>trying contact grain technology inc debt owed ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164880</th>\n",
       "      <td>bought large rug start vacation called filed d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463976</th>\n",
       "      <td>original complaint went car dealership ohio lo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490359</th>\n",
       "      <td>synopsis loan demand estate loan originated an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316427</th>\n",
       "      <td>may concern writing dispute fraudulent charge ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     lemon  Older American  \\\n",
       "48045    trying contact grain technology inc debt owed ...               0   \n",
       "1164880  bought large rug start vacation called filed d...               0   \n",
       "463976   original complaint went car dealership ohio lo...               0   \n",
       "490359   synopsis loan demand estate loan originated an...               0   \n",
       "316427   may concern writing dispute fraudulent charge ...               0   \n",
       "\n",
       "         Older American, Servicemember  Servicemember  credit_card  \\\n",
       "48045                                0              0            0   \n",
       "1164880                              0              0            1   \n",
       "463976                               0              0            0   \n",
       "490359                               0              0            0   \n",
       "316427                               0              0            0   \n",
       "\n",
       "         credit_report  debt_collection  loans  money_service  mortgage  \n",
       "48045                0                1      0              0         0  \n",
       "1164880              0                0      0              0         0  \n",
       "463976               1                0      0              0         0  \n",
       "490359               0                0      0              0         1  \n",
       "316427               1                0      0              0         0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_train1 = int(round(len(train[train.company_response_to_consumer=='Closed with explanation'])*.2,0))\n",
    "sm_train2 = int(round(len(train[train.company_response_to_consumer=='Closed with non-monetary relief'])*.2,0))\n",
    "sm_train3 = int(round(len(train[train.company_response_to_consumer=='Closed with monetary relief'])*.2,0))\n",
    "sm_train4 = int(round(len(train[train.company_response_to_consumer=='Untimely response'])*.2,0))\n",
    "sm_train5 = int(round(len(train[train.company_response_to_consumer=='Closed'])*.2,0))\n",
    "sm_val1 = int(round(len(validate[validate.company_response_to_consumer=='Closed with explanation'])*.2,0))\n",
    "sm_val2 = int(round(len(validate[validate.company_response_to_consumer=='Closed with non-monetary relief'])*.2,0))\n",
    "sm_val3 = int(round(len(validate[validate.company_response_to_consumer=='Closed with monetary relief'])*.2,0))\n",
    "sm_val4 = int(round(len(validate[validate.company_response_to_consumer=='Untimely response'])*.2,0))\n",
    "sm_val5 = int(round(len(validate[validate.company_response_to_consumer=='Closed'])*.2,0))\n",
    "sm_test1 = int(round(len(test[test.company_response_to_consumer=='Closed with explanation'])*.2,0))\n",
    "sm_test2 = int(round(len(test[test.company_response_to_consumer=='Closed with non-monetary relief'])*.2,0))\n",
    "sm_test3 = int(round(len(test[test.company_response_to_consumer=='Closed with monetary relief'])*.2,0))\n",
    "sm_test4 = int(round(len(test[test.company_response_to_consumer=='Untimely response'])*.2,0))\n",
    "sm_test5 = int(round(len(test[test.company_response_to_consumer=='Closed'])*.2,0))\n",
    "\n",
    "small_train1 = train[train.company_response_to_consumer=='Closed with explanation'].sample(sm_train1,random_state=123)\n",
    "small_train2 = train[train.company_response_to_consumer=='Closed with non-monetary relief'].sample(sm_train2,random_state=123)\n",
    "small_train3 = train[train.company_response_to_consumer=='Closed with monetary relief'].sample(sm_train3,random_state=123)\n",
    "small_train4 = train[train.company_response_to_consumer=='Untimely response'].sample(sm_train4,random_state=123)\n",
    "small_train5 = train[train.company_response_to_consumer=='Closed'].sample(sm_train5,random_state=123)\n",
    "small_val1 = validate[validate.company_response_to_consumer=='Closed with explanation'].sample(sm_val1,random_state=123)\n",
    "small_val2 = validate[validate.company_response_to_consumer=='Closed with non-monetary relief'].sample(sm_val2,random_state=123)\n",
    "small_val3 = validate[validate.company_response_to_consumer=='Closed with monetary relief'].sample(sm_val3,random_state=123)\n",
    "small_val4 = validate[validate.company_response_to_consumer=='Untimely response'].sample(sm_val4,random_state=123)\n",
    "small_val5 = validate[validate.company_response_to_consumer=='Closed'].sample(sm_val5,random_state=123)\n",
    "small_test1 = test[test.company_response_to_consumer=='Closed with explanation'].sample(sm_test1,random_state=123)\n",
    "small_test2 = test[test.company_response_to_consumer=='Closed with non-monetary relief'].sample(sm_test2,random_state=123)\n",
    "small_test3 = test[test.company_response_to_consumer=='Closed with monetary relief'].sample(sm_test3,random_state=123)\n",
    "small_test4 = test[test.company_response_to_consumer=='Untimely response'].sample(sm_test4,random_state=123)\n",
    "small_test5 = test[test.company_response_to_consumer=='Closed'].sample(sm_test5,random_state=123)\n",
    "\n",
    "small_train = pd.concat([small_train1,small_train2,small_train3,small_train4,small_train5])\n",
    "small_val = pd.concat([small_val1,small_val2,small_val3,small_val4,small_val5])\n",
    "small_test = pd.concat([small_test1,small_test2,small_test3,small_test4,small_test5])\n",
    "\n",
    "X_train = m.encode(small_train)\n",
    "X_train = X_train.drop(columns=['date_received','company_response_to_consumer','clean','state','company_name','tags','product_bins'])\n",
    "y_train = small_train['company_response_to_consumer']\n",
    "X_val = m.encode(small_val)\n",
    "X_val = X_val.drop(columns=['date_received','company_response_to_consumer','clean','state','company_name','tags','product_bins'])\n",
    "y_val = small_val['company_response_to_consumer']\n",
    "X_test = m.encode(small_test)\n",
    "X_test = X_test.drop(columns=['date_received','company_response_to_consumer','clean','state','company_name','tags','product_bins'])\n",
    "y_test = small_test['company_response_to_consumer']\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf67c0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d420e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv,X_val_cv,X_test_cv = m.make_cv(X_train, X_val, X_test)\n",
    "X_train_tf,X_val_tf,X_test_tf = m.make_tfidf(X_train, X_val, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5169ba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = X_train.iloc[:,1:]\n",
    "encoded_val = X_val.iloc[:,1:]\n",
    "encoded_test = X_test.iloc[:,1:]\n",
    "\n",
    "X_train_cve = encoded_train.merge(X_train_cv,left_index=True, right_index=True)\n",
    "X_val_cve = encoded_val.merge(X_val_cv,left_index=True, right_index=True)\n",
    "X_test_cve = encoded_test.merge(X_test_cv,left_index=True, right_index=True)\n",
    "\n",
    "X_train_tfe = encoded_train.merge(X_train_tf,left_index=True, right_index=True)\n",
    "X_val_tfe = encoded_val.merge(X_val_tf,left_index=True, right_index=True)\n",
    "X_test_tfe = encoded_test.merge(X_test_tf,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c5e99c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def xgboost_hyperparam_search(X_train, y_train, X_val, y_val, hyperparams):\n",
    "    results = []\n",
    "    \n",
    "    for params in hyperparams:\n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        train_pred = model.predict(X_train)\n",
    "        train_acc = accuracy_score(y_train, train_pred)\n",
    "        \n",
    "        val_pred = model.predict(X_val)\n",
    "        val_acc = accuracy_score(y_val, val_pred)\n",
    "        \n",
    "        results.append({'Parameters': params, 'Train Accuracy': train_acc, 'Validation Accuracy': val_acc})\n",
    "    \n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results = df_results.sort_values(by='Validation Accuracy', ascending=False).head(10)\n",
    "    \n",
    "    # Plotting the top 10 models\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(df_results) + 1), df_results['Train Accuracy'], label='Train Accuracy')\n",
    "    plt.plot(range(1, len(df_results) + 1), df_results['Validation Accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Top 10 Models - Train vs Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.xticks(range(1, len(df_results) + 1))\n",
    "    plt.show()\n",
    "    \n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "353af5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = [\n",
    "    {'max_depth': 3, 'learning_rate': 0.1, 'n_estimators': 100},\n",
    "    {'max_depth': 5, 'learning_rate': 0.05, 'n_estimators': 200},\n",
    "    {'max_depth': 3, 'learning_rate': 0.01, 'n_estimators': 500}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19757b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058d6c45",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb7bd0fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wd/5_z1tvw94pv9x2ld8p_0dl2r0000gn/T/ipykernel_2578/2688289166.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgboost_hyperparam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_cve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_cve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/wd/5_z1tvw94pv9x2ld8p_0dl2r0000gn/T/ipykernel_2578/2373199247.py\u001b[0m in \u001b[0;36mxgboost_hyperparam_search\u001b[0;34m(X_train, y_train, X_val, y_val, hyperparams)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhyperparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1488\u001b[0m             )\n\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1491\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1919\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgboost_hyperparam_search(X_train_cve, y_train_encoded, X_val_cve, y_val_encoded, hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bdba90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
